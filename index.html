<!DOCTYPE html>












  


<html class="theme-next pisces use-motion" lang>
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">












  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.2.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.2.0">


  <link rel="mask-icon" href="/images/logo.svg?v=7.2.0" color="#222">






<link rel="stylesheet" href="/css/main.css?v=7.2.0">






<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">








<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.2.0',
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="description" content="有志者，事竟成">
<meta name="keywords" content="NLP、DeepLearning、Machine Learning">
<meta property="og:type" content="website">
<meta property="og:title" content="SStarLib&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="SStarLib&#39;s Blog">
<meta property="og:description" content="有志者，事竟成">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SStarLib&#39;s Blog">
<meta name="twitter:description" content="有志者，事竟成">





  
  
  <link rel="canonical" href="http://yoursite.com/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  
  <title>SStarLib's Blog</title>
  












  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SStarLib's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home menu-item-active">

    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-about">

    
    
      
    

    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-schedule">

    
    
      
    

    

    <a href="/schedule/" rel="section"><i class="menu-item-icon fa fa-fw fa-calendar"></i> <br>Schedule</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-sitemap">

    
    
      
    

    

    <a href="/sitemap.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>Sitemap</a>

  </li>

      
      
    </ul>
  

  

  
</nav>



</div>
    </header>

    
  
  

  

  <a href="https://github.com/SStarLib" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewbox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a>



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/18/命名实体识别学习-用lstm-crf处理conll03数据集/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wei">
      <meta itemprop="description" content="有志者，事竟成">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SStarLib's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/07/18/命名实体识别学习-用lstm-crf处理conll03数据集/" class="post-title-link" itemprop="url">命名实体识别学习-用lstm+crf处理conll03数据集</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2020-07-18 16:32:31" itemprop="dateCreated datePublished" datetime="2020-07-18T16:32:31+08:00">2020-07-18</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-07-19 00:48:46" itemprop="dateModified" datetime="2020-07-19T00:48:46+08:00">2020-07-19</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="命名实体识别学习-用lstm-crf处理conll03数据集"><a href="#命名实体识别学习-用lstm-crf处理conll03数据集" class="headerlink" title="命名实体识别学习-用lstm+crf处理conll03数据集"></a><center>命名实体识别学习-用lstm+crf处理conll03数据集</center></h1><p>[TOC]</p>
<p>一直想写的一篇文章，虽然好像也不是很忙，但是一直拖着没做。就是讲下面两篇文章介绍的数据集和算法做一个整合</p>
<p><a href="https://blog.csdn.net/StarLib/article/details/107350559" target="_blank" rel="noopener">命名实体识别学习-数据集介绍-conll03</a></p>
<p><a href="https://blog.csdn.net/StarLib/article/details/106933974" target="_blank" rel="noopener">命名实体识别学习-从基础算法开始（02）lstm+crf序列标注</a></p>
<h2 id="一-整合时要解决的问题"><a href="#一-整合时要解决的问题" class="headerlink" title="一 整合时要解决的问题"></a>一 整合时要解决的问题</h2><ol>
<li><p>要为数据和模型读入设计合理的数据结构：即vocab-vecterizer-dataset这个pipeline，几乎所有的nlp任务都要走这个pipeline的模式（看别人的源码发现，真正实现这些数据结构时代码五花八门，不过数据结构本来就是ADT的物理实现，只要把核心功能实现就好了。）</p>
</li>
<li><p>原有的算法是一句一句读入的，我实现的时候要用mini-batch, mini-batch已经被证明了其在深度学习应用的作用和功能。不过应用mini-batch要考虑输入句子长短不一的问题，使用pad和mask的技术，尽量避免模型看到pad的元素。本模型主要有三处用到，第一是lstm读入时，然后是crf的算句子得分，和loss计算的时候。在这三处要用mask的方法避免模型读到pad的元素。</p>
</li>
<li><p>原代码，即pytorch官网上放的教程为了使代码便于理解，使用了很多for循环，不利于cuda对代码的加速，尽量将能够变为矩阵运算的for循环变为矩阵的计算。</p>
</li>
</ol>
<p>要解决的三个问题：<code>数据结构，pad和mask，for循环改为矩阵计算</code>。还有一个使代码可以在GPU上运行。（不过我自己最近没法找到卡，所以代码都是凭感觉debug的，不过这次代码已经在学弟卡上跑过了）</p>
<h2 id="二-mask和pad"><a href="#二-mask和pad" class="headerlink" title="二 mask和pad"></a>二 mask和pad</h2><p>变长序列的处理是深度学习框架的一大难题，各个框架都有比较成熟的解决问题，</p>
<h3 id="lstm读入"><a href="#lstm读入" class="headerlink" title="lstm读入"></a>lstm读入</h3><p>其中pytorch为RNN的读入专门做了处理。所以对于lstm读入时处理就很简单，只需简单调用torch.nn.utils.rnn.pack_padded_sequence()和torch.nn.utils.rnn.pad_packed_sequence即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_lstm_features</span><span class="params">(self, embedded_vec, seq_len)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        :param embedded_vec: [max_seq_len, b_s, e_d]</span></span><br><span class="line"><span class="string">        :param seq_len: [b_s]</span></span><br><span class="line"><span class="string">        :return:</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># 初始化 h0 和 c0,可以缺省 shape:</span></span><br><span class="line">        <span class="comment"># ([num_layers * num_directions, batch, hidden_size],[num_layers * num_directions, batch, hidden_size])</span></span><br><span class="line">        <span class="comment"># self.hidden = self.init_hidden(1, seq_len.size(0))</span></span><br><span class="line">        pack_seq = pack_padded_sequence(embedded_vec, seq_len)</span><br><span class="line">        <span class="comment"># 不初始化状态，默认初始状态都为0</span></span><br><span class="line">        <span class="comment"># lstm_out, self.hidden = self.lstm(pack_seq, self.hidden)</span></span><br><span class="line">        lstm_out, self.hidden = self.lstm(pack_seq)</span><br><span class="line">        lstm_out, _ = pad_packed_sequence(lstm_out, batch_first=<span class="literal">True</span>) <span class="comment">#[b_s, seq_len, h_d]</span></span><br><span class="line">        lstm_feats = self.hidden2tag(lstm_out)  <span class="comment">#[b_s, seq_len, tag_size]</span></span><br><span class="line">        lstm_feats = self.dropout(lstm_feats)</span><br><span class="line">        <span class="keyword">return</span> lstm_feats</span><br></pre></td></tr></table></figure>

<p> 注意：使用这两个自带函数有个问题，并不能恢复百分百恢复原来的输入，他恢复后的句长是输入最长句子的长度，也就是说如果你输入时最长句子也有一定长度的pad元素，那样是没办法恢复的。</p>
<h3 id="涉及转移分矩阵的计算"><a href="#涉及转移分矩阵的计算" class="headerlink" title="涉及转移分矩阵的计算"></a>涉及转移分矩阵的计算</h3><p>第二处mask是在转移分的计算，因为self.transitions给pad元素留了位置，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">self.transition = nn.Parameter(</span><br><span class="line">            torch.randn(self.tagset_size, self.tagset_size))</span><br></pre></td></tr></table></figure>

<p>这其实不符合我们尽量避免模型看到pad元素的原则（我尝试不在transition里给pad留位置，但是由于 变长序列总会有pad元素，如果没有pad元素的位置，索引就会报错。）这里我使用折中处理，在涉及到转移分矩阵的运算并直接关联结果的都mask掉，（其实存在于矩阵里无所谓，只要最后计算不影响结果即可。</p>
<p>涉及到转移分的计算，主要是loss的计算，在官网文档里：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">neg_log_likelihood</span><span class="params">(self, sentence, tags)</span>:</span></span><br><span class="line">    feats = self._get_lstm_features(sentence)</span><br><span class="line">    forward_score = self._forward_alg(feats)</span><br><span class="line">    gold_score = self._score_sentence(feats, tags)</span><br><span class="line">    <span class="keyword">return</span> forward_score - gold_score</span><br></pre></td></tr></table></figure>

<p>其中，gold_score的计算和forward_score的计算都需要mask机制。</p>
<p>首先是得到mask：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mask = (token_vec != self.token_vocab.lookup_token(self.pad)).to(self.device)  <span class="comment"># [b_s, max_seq_len]</span></span><br></pre></td></tr></table></figure>

<p>这个token_vec就是句子向量，mask是一个布尔值向量，其中不等于pad的位置为true，等于pad的位置为false。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">def _score_sentence(self, feats, tags):</span><br><span class="line">    # Gives the score of a provided tag sequence</span><br><span class="line">    score = torch.zeros(1)</span><br><span class="line">    tags = torch.cat([torch.tensor([ self.tag_to_ix[START_TAG]], dtype=torch.long), tags ])</span><br><span class="line">    for i, feat in enumerate(feats):</span><br><span class="line">        score = score + \</span><br><span class="line">            self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]</span><br><span class="line">    score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]</span><br><span class="line">    return score</span><br></pre></td></tr></table></figure>

<p>这个gold_score的代码相对简单：逻辑就是把真实tag对应的转移分和发射分相加，（其实这里的for循环可以去掉换成矩阵运算）因为feats中每个句子（即每个时间步）都参与一次计算，且可能有pad元素，对mask的处理：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">total_score = (score * mask.type(torch.float)).sum(dim=1)</span><br></pre></td></tr></table></figure>

<p>forward_score出的mask的处理，官网关于foward_score的计算比较长，就不放了，简述下逻辑，forward_score的计算本质上就是前向算法，前向算法就是DP。（在前面的博客里介绍的比较详细）在每个时间步里求前向变量，而我们用了mini-batch那么一个时间步计算的就不是一个token了。而是一批token，而由于一个mini-batch里句子是不等长的，可能一个句子还没结束，其他句子就已经运算的pad元素了，所以要用mask机制避免pad元素参与到运算中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> feat_index <span class="keyword">in</span> range(<span class="number">1</span>, feats.size(<span class="number">1</span>)):</span><br><span class="line">    n_unfinish = mask[:, feat_index].sum()</span><br><span class="line">    d_uf = d[:n_unfinish] <span class="comment">#[uf, 1, tag_size]</span></span><br></pre></td></tr></table></figure>

<p>这里是直接算出非pad元素的个数，因为我们的输入是按句长排列的，所以可以直接取前n_finish个进行计算。</p>
<h2 id="三-将for循环改为矩阵运算"><a href="#三-将for循环改为矩阵运算" class="headerlink" title="三 将for循环改为矩阵运算"></a>三 将for循环改为矩阵运算</h2><p>原官网代码为了代码可读性，使用的了几处for循环，是可以用矩阵运算代替的，同时代码里的前向算法和维特比解码算法是动态规划算法，可能是不适合改为矩阵运算（不过也不一定，可能有大神实现了）</p>
<p><code>哪些可以改为for循环？</code>这个问题我也没有查到，<del>我的理解就是看能不能并行，能并行的话大部分都可以用矩阵运算</del>（这是句废话），当然如何分析能不能并行，这个还有待后续查资料继续学习。</p>
<h3 id="gold-score的计算"><a href="#gold-score的计算" class="headerlink" title="gold_score的计算"></a>gold_score的计算</h3><p>在计算neg_log_likelihood时需要计算gold_score,其代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_score_sentence</span><span class="params">(self, feats, tags)</span>:</span></span><br><span class="line">        <span class="comment"># Gives the score of a provided tag sequence</span></span><br><span class="line">        score = torch.zeros(<span class="number">1</span>)</span><br><span class="line">        tags = torch.cat([torch.tensor([ self.tag_to_ix[START_TAG]], dtype=torch.long), tags ])</span><br><span class="line">        <span class="keyword">for</span> i, feat <span class="keyword">in</span> enumerate(feats):</span><br><span class="line">            score = score + \</span><br><span class="line">                self.transitions[tags[i + <span class="number">1</span>], tags[i]] + feat[tags[i + <span class="number">1</span>]]</span><br><span class="line">        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[<span class="number">-1</span>]]</span><br><span class="line">        <span class="keyword">return</span> score</span><br></pre></td></tr></table></figure>

<p>但看这段代码，因为score计算依赖上一个时间步的score，乍一看似乎不能无法更改（不能因为依赖上一步的结果就认为是个dp算法，关键看有没有最优子结构），不过稍加分析，其实这个是最容易改为矩阵计算的，证明如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">score0=transition[tags[1], tags[0]]+feat[tags[1]]</span><br><span class="line">score1=score0+transition[tags[2], tags[1]]+feat[tags[2]]</span><br><span class="line">...</span><br><span class="line">scorei+1=scorei+transition[tags[i+1], tags[i]]+feats[tags[i+1]]</span><br><span class="line"></span><br><span class="line">score=score0+score1+...+scorei+1=transition[tags[1], tags[0]]+feat[tags[1]]+...+transition[tags[i+1], tag[i]]+feat[tags[i+1]]</span><br></pre></td></tr></table></figure>

<p>从上面的分析，很容易将这段代码改为矩阵计算，同时加上mask机制。最终代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_score_sentence</span><span class="params">(self, feats, tags, mask)</span>:</span></span><br><span class="line">    score = torch.gather(feats, dim=<span class="number">2</span>, index=tags.unsqueeze(dim=<span class="number">2</span>)).squeeze(dim=<span class="number">2</span>)</span><br><span class="line">    score[:, <span class="number">1</span>:] += self.transition[tags[:, :<span class="number">-1</span>], tags[:, <span class="number">1</span>:]]</span><br><span class="line">    total_score = (score * mask.type(torch.float)).sum(dim=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> total_score</span><br></pre></td></tr></table></figure>

<h3 id="forward-score的计算"><a href="#forward-score的计算" class="headerlink" title="forward_score的计算"></a>forward_score的计算</h3><p>原官网的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_forward_alg</span><span class="params">(self, feats)</span>:</span></span><br><span class="line">       <span class="comment"># Do the forward algorithm to compute the partition function</span></span><br><span class="line">       init_alphas = torch.full((<span class="number">1</span>, self.tagset_size), <span class="number">-10000.</span>)</span><br><span class="line">       <span class="comment"># START_TAG has all of the score.</span></span><br><span class="line">       init_alphas[<span class="number">0</span>][self.tag_to_ix[START_TAG]] = <span class="number">0.</span></span><br><span class="line"></span><br><span class="line">       <span class="comment"># Wrap in a variable so that we will get automatic backprop</span></span><br><span class="line">       forward_var = init_alphas</span><br><span class="line"></span><br><span class="line">       <span class="comment"># Iterate through the sentence</span></span><br><span class="line">       <span class="keyword">for</span> feat <span class="keyword">in</span> feats:</span><br><span class="line">           alphas_t = []  <span class="comment"># The forward tensors at this timestep</span></span><br><span class="line">           <span class="keyword">for</span> next_tag <span class="keyword">in</span> range(self.tagset_size):</span><br><span class="line">               <span class="comment"># broadcast the emission score: it is the same regardless of</span></span><br><span class="line">               <span class="comment"># the previous tag</span></span><br><span class="line">               emit_score = feat[next_tag].view(</span><br><span class="line">                   <span class="number">1</span>, <span class="number">-1</span>).expand(<span class="number">1</span>, self.tagset_size)</span><br><span class="line">               <span class="comment"># the ith entry of trans_score is the score of transitioning to</span></span><br><span class="line">               <span class="comment"># next_tag from i</span></span><br><span class="line">               trans_score = self.transitions[next_tag].view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">               <span class="comment"># The ith entry of next_tag_var is the value for the</span></span><br><span class="line">               <span class="comment"># edge (i -&gt; next_tag) before we do log-sum-exp</span></span><br><span class="line">               next_tag_var = forward_var + trans_score + emit_score</span><br><span class="line">               <span class="comment"># The forward variable for this tag is log-sum-exp of all the</span></span><br><span class="line">               <span class="comment"># scores.</span></span><br><span class="line">               alphas_t.append(log_sum_exp(next_tag_var).view(<span class="number">1</span>))</span><br><span class="line">           forward_var = torch.cat(alphas_t).view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">       terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]</span><br><span class="line">       alpha = log_sum_exp(terminal_var)</span><br><span class="line">       <span class="keyword">return</span> alpha</span><br></pre></td></tr></table></figure>

<p>下面简单分析下,假设tag_size=2，值集合为：{0,1}</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">emit_score=feat[0].expand(1, self.tagset_size) #经过扩展emit_score变为shape为[1，2]的矩阵，因为pytorch的广播机制，其实就是[feat[0], feat[0]]</span><br><span class="line">trans_score = self.transitions[0].view(1, -1)# 这个本身就是shape为[1，2]的矩阵，表示tag分别从0，1转为0的转移分。</span><br><span class="line">next_tag_var0= forward_var + trans_score + emit_score=forward_var +[feat[0], feat[0]]+self.transitions[0]</span><br><span class="line"></span><br><span class="line"># 下一个迭代</span><br><span class="line">emit_score=feat[1].expand(1, self.tagset_size) #经过扩展emit_score变为shape为[1，2]的矩阵，因为pytorch的广播机制，其实就是[feat[0], feat[0]]</span><br><span class="line">trans_score = self.transitions[1].view(1, -1)# 这个本身就是shape为[1，2]的矩阵，表示tag分别从0，1转为0的转移分。</span><br><span class="line">next_tag_var1= forward_var + trans_score + emit_score=forward_var +[feat[1], feat[1]]+self.transitions[1]</span><br><span class="line"></span><br><span class="line">从这个分析很明显可以看出可以转为矩阵计算，大致思路为：</span><br><span class="line">next_tag_var = forward_var+feats.unsqueeze(dim=1)+self.transitions</span><br><span class="line"></span><br><span class="line">其中：</span><br><span class="line">feat.unsqueeze(dim=1)+self.transitions # shape为[tag_size, tag_size]</span><br><span class="line">forward_var的shape为[1，tag_size]， 这里的矩阵计算，会通过广播机制，自动复制其自身的值。</span><br></pre></td></tr></table></figure>

<p>加上batch所处的维度，刚好是三维张量的计算，是一个比较习惯处理的维度，再加去掉for循环，加高维度没有必要。最终结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_forward_alg</span><span class="params">(self, feats, mask)</span>:</span></span><br><span class="line">    <span class="string">"""前向算法</span></span><br><span class="line"><span class="string">    :param feats: [b_s, seq_len, tag_size]</span></span><br><span class="line"><span class="string">    :param mask: [b_s, seq_len]</span></span><br><span class="line"><span class="string">    :return:</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="comment"># Do the forward algorithm to compute the partition function</span></span><br><span class="line">    init_alphas = torch.full((feats.size(<span class="number">0</span>), self.tagset_size), <span class="number">-10000.</span>, device=self.device)    <span class="comment">#[b_s, tag_size]</span></span><br><span class="line">    <span class="comment"># START_TAG has all of the score.along dim=1,</span></span><br><span class="line">    init_alphas[:, self.begin_tag_idx]=<span class="number">0.</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Wrap in a variable so that we will get automatic backprop</span></span><br><span class="line">    forward_var_list=[]</span><br><span class="line">    forward_var_list.append(init_alphas)</span><br><span class="line">    d = torch.unsqueeze(feats[:,<span class="number">0</span>], dim=<span class="number">1</span>)  <span class="comment">#[b_s, 1, tag_size]</span></span><br><span class="line">    <span class="keyword">for</span> feat_index <span class="keyword">in</span> range(<span class="number">1</span>, feats.size(<span class="number">1</span>)):</span><br><span class="line">        n_unfinish = mask[:, feat_index].sum()</span><br><span class="line">        d_uf = d[:n_unfinish] <span class="comment">#[uf, 1, tag_size]</span></span><br><span class="line">        emit_and_transition = feats[: n_unfinish, feat_index].unsqueeze(dim=<span class="number">1</span>)+self.transition <span class="comment">#[uf,tag_size,tag_size]</span></span><br><span class="line">        log_sum = d_uf.transpose(<span class="number">1</span>, <span class="number">2</span>)+emit_and_transition  <span class="comment">#[uf, tag_size, tag_size]</span></span><br><span class="line">        max_v = log_sum.max(dim=<span class="number">1</span>)[<span class="number">0</span>].unsqueeze(dim=<span class="number">1</span>)  <span class="comment">#[uf, 1, tag_size]</span></span><br><span class="line">        log_sum = log_sum - max_v   <span class="comment">#[uf, tag_size, tag_size]</span></span><br><span class="line">        d_uf = max_v + torch.logsumexp(log_sum, dim=<span class="number">1</span>).unsqueeze(dim=<span class="number">1</span>) <span class="comment"># [uf, 1, tag_size]</span></span><br><span class="line">        d = torch.cat((d_uf, d[n_unfinish:]), dim=<span class="number">0</span>)</span><br><span class="line">    d = d.squeeze(dim=<span class="number">1</span>)    <span class="comment">#[b_s, tag_size]</span></span><br><span class="line">    max_d = d.max(dim=<span class="number">-1</span>)[<span class="number">0</span>]  <span class="comment"># [b_s]</span></span><br><span class="line">    d = max_d + torch.logsumexp(d - max_d.unsqueeze(dim=<span class="number">1</span>), dim=<span class="number">1</span>)  <span class="comment"># [b_s]</span></span><br><span class="line">    <span class="keyword">return</span> d</span><br></pre></td></tr></table></figure>

<p>维特比解码算法的修改思路和前向算法大致一致，修改后的代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_viterbi_decode</span><span class="params">(self, feats, mask, seq_len)</span>:</span></span><br><span class="line">    batch_size = feats.size(<span class="number">0</span>)</span><br><span class="line">    tags = [[[i] <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.tag_vocab))]] * batch_size  <span class="comment"># list, shape: (b, K, 1)</span></span><br><span class="line">    d = torch.unsqueeze(feats[:, <span class="number">0</span>], dim=<span class="number">1</span>)  <span class="comment"># shape: (b, 1, K)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, seq_len[<span class="number">0</span>]):</span><br><span class="line">        n_unfinished = mask[:, i].sum()</span><br><span class="line">        d_uf = d[: n_unfinished]  <span class="comment"># shape: (uf, 1, K)</span></span><br><span class="line">        emit_and_transition = self.transition + feats[: n_unfinished, i].unsqueeze(dim=<span class="number">1</span>)  <span class="comment"># shape: (uf, K, K)</span></span><br><span class="line">        new_d_uf = d_uf.transpose(<span class="number">1</span>, <span class="number">2</span>) + emit_and_transition  <span class="comment"># shape: (uf, K, K)</span></span><br><span class="line">        d_uf, max_idx = torch.max(new_d_uf, dim=<span class="number">1</span>)</span><br><span class="line">        max_idx = max_idx.tolist()  <span class="comment"># list, shape: (nf, K)</span></span><br><span class="line">        tags[: n_unfinished] = [[tags[b][k] + [j] <span class="keyword">for</span> j, k <span class="keyword">in</span> enumerate(max_idx[b])] <span class="keyword">for</span> b <span class="keyword">in</span> range(n_unfinished)]</span><br><span class="line">        d = torch.cat((torch.unsqueeze(d_uf, dim=<span class="number">1</span>), d[n_unfinished:]), dim=<span class="number">0</span>)  <span class="comment"># shape: (b, 1, K)</span></span><br><span class="line">    d = d.squeeze(dim=<span class="number">1</span>)  <span class="comment"># [b_s, tag_size</span></span><br><span class="line">    score, max_idx = torch.max(d, dim=<span class="number">1</span>)  <span class="comment"># shape: (b,)</span></span><br><span class="line">    max_idx = max_idx.tolist()</span><br><span class="line">    tags = [tags[b][k] <span class="keyword">for</span> b, k <span class="keyword">in</span> enumerate(max_idx)]</span><br><span class="line">    <span class="keyword">return</span> score, tags</span><br></pre></td></tr></table></figure>

<p>整个工程代码地址：<a href="https://github.com/SStarLib/NERfromBasic/tree/master/Day03minibatch-lstm%2Bcrfs/conll03Ner" target="_blank" rel="noopener">https://github.com/SStarLib/NERfromBasic/tree/master/Day03minibatch-lstm%2Bcrfs/conll03Ner</a></p>
<h2 id="结果："><a href="#结果：" class="headerlink" title="结果："></a>结果：</h2><p>![image-20200719003342138](/Users/wei/Library/Application Support/typora-user-images/image-20200719003342138.png)</p>
<p>这个是加入了预训练embedding的结果，比不加稍微好一点。不过好的有限。甚至有的地方还要更差。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>整个工程代码花费了接近一天的时间，写代码的时候出现了各种奇奇怪怪的bug，有的是变量命名差个s，结果写的时候没有注意出错，好不容易调通了，结果发现loss一直不变化，我还以为是我的代码实现的有问题，结果把代码改的面目全非，甚至很多地方已经背离了我最初的思路了，几乎是把整个工程推翻重写，最后debug时，发现lstm生成的feats几乎不变化，才开始意识到模型根本没起作用，最终发现是因为没有对模型参数初始化的原因，（真的是太久不写pytorch的代码了，连模型参数初始化都先不起来）虽然最后整个工程项目成功了，但是花费了大量时间，<code>真的，写出bug free的工程代码是一个人素质的体现!</code></p>
<p>关于加入了预训练embedding的结果不显著的问题，可能是glove，只有小写字母，而字母的大小写本身就是实体的一个重要特征，使用了glove反而可能丢失了这个重要特征，解决办法是加入char embedding ,下次可以在模型中加入，或者一步到位，使用Elmo的embedding，</p>
<p>尽量要使用 mini batch </p>
<p>for循环改为矩阵计算，提高并行性，提升运算速度很重要，一般常用的都是三维张量，包含一维batch，所以尽量改成三维张量的运算为好。</p>
<p>pad和mask机制的使用，有空可以专门写一篇文章，介绍这个，并总结一下。</p>
<p>pipeline的数据结构，有空了再介绍吧，不难，主要是要明确要实现的功能，并抽象出来，然后用代码实现即可。</p>
<p>一直想要系统性的学一下pytorch，可是到现在连本相关的书都没买过，（甚至30分钟的官网视频也没看），甚至不知道pytorch能做啥不能做啥。所以我的coding过程非常痛苦，使用google的频率非常高。pytorch的api，几乎要不停的查。<code>磨刀不误砍柴工</code>,真的应该系统性的学习下这个框架，然后再想着复现论文。</p>
<p>比赛的时候一定不会用pytorch，相比keras的搭积木似的coding过程，pytorch的开发周期确实有点长了，甚至要一直照顾shape，所以我在我的代码里要一直备注shape的变化，和广播机制将要怎么发生。</p>
<p>要好好了解下pytorch的广播机制，这个是代码可读性的天敌，不好好了解，有时候无法看懂别人的代码。</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/14/命名实体识别学习-数据集介绍-conll03/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wei">
      <meta itemprop="description" content="有志者，事竟成">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SStarLib's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/07/14/命名实体识别学习-数据集介绍-conll03/" class="post-title-link" itemprop="url"> 命名实体识别学习-数据集介绍-conll03 </a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2020-07-14 22:46:05 / Modified: 23:47:11" itemprop="dateCreated datePublished" datetime="2020-07-14T22:46:05+08:00">2020-07-14</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="命名实体识别学习-数据集介绍-conll03"><a href="#命名实体识别学习-数据集介绍-conll03" class="headerlink" title="命名实体识别学习-数据集介绍-conll03 "></a><center>命名实体识别学习-数据集介绍-conll03 </center></h1><p>[TOC]</p>
<p>conll 2003 是命名实体中最常见的公开数据集。其官网：<a href="https://www.clips.uantwerpen.be/conll2003/ner/" target="_blank" rel="noopener">https://www.clips.uantwerpen.be/conll2003/ner/</a></p>
<p>有很详细的介绍。</p>
<h2 id="一-类别个数"><a href="#一-类别个数" class="headerlink" title="一 类别个数"></a>一 类别个数</h2><blockquote>
<p>Named entities are phrases that contain the names of persons, organizations, locations, times and quantities. Example:</p>
<p>[ORG U.N. ] official [PER Ekeus ] heads for [LOC Baghdad ] .</p>
<p>The shared task of <a href="https://www.clips.uantwerpen.be/conll2003/" target="_blank" rel="noopener">CoNLL-2003</a> concerns language-independent named entity recognition. <code>We will concentrate on four types of named entities: persons, locations, organizations and names of miscellaneous entities that do not belong to the previous three groups.</code>The participants of the shared task will be offered training and test data for two languages. They will use the data for developing a named-entity recognition system that includes a machine learning component. For each language, additional information (lists of names and non-annotated data) will be supplied as well. The challenge for the participants is to find ways of incorporating this information in their system.</p>
</blockquote>
<p>上文来自官网，高亮部分介绍其所要分的类别。总共四类：persons, locations, organizations ,miscellaneous entities</p>
<h2 id="二-数据集样例"><a href="#二-数据集样例" class="headerlink" title="二 数据集样例"></a>二 数据集样例</h2><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1ggqwr59opjj30i20e83zq.jpg" alt="image-20200714231551083"></p>
<p>这是其训练集中某个部分。</p>
<p>通过其官网介绍，可知改数据集第一例是单词，第二列是词性，第三列是语法快，第四列是实体标签。在NER任务中，只关心第一列和第四列。实体类别标注采用BIO标注法，前面博客介绍这种标注法。</p>
<p>以下是官网的介绍：</p>
<p>The CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on a separate line and there is an empty line after each sentence. The first item on each line is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only if two phrases of the same type immediately follow each other, the first word of the second phrase will have tag B-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Here is an example:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">U.N.         NNP  I-NP  I-ORG </span><br><span class="line">official     NN   I-NP  O </span><br><span class="line">Ekeus        NNP  I-NP  I-PER </span><br><span class="line">heads        VBZ  I-VP  O </span><br><span class="line">for          IN   I-PP  O </span><br><span class="line">Baghdad      NNP  I-NP  I-LOC </span><br><span class="line">.            .    O     O</span><br></pre></td></tr></table></figure>

<p>The data consists of three files per language: one training file and two test files testa and testb. The first test file will be used in the development phase for finding good parameters for the learning system. The second test file will be used for the final evaluation. There are data files available for English and German. The German files contain an extra column (the second) which holds the lemma of each word.</p>
<h2 id="三-预处理"><a href="#三-预处理" class="headerlink" title="三 预处理"></a>三 预处理</h2><p>上面已经介绍了数据集的结构，同时，我们想要将数据输入变为下面这种数据结构，所以要对文本数据做一定处理：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"> [(</span><br><span class="line">    &quot;the wall street journal reported today that apple corporation made money&quot;.split(),</span><br><span class="line">    &quot;B I I I O O O B I O O&quot;.split()</span><br><span class="line">), (</span><br><span class="line">    &quot;georgia tech is a university in georgia&quot;.split(),</span><br><span class="line">    &quot;B I O O O O B&quot;.split()</span><br><span class="line">)]</span><br></pre></td></tr></table></figure>

<p>上面代码在<a href="https://blog.csdn.net/StarLib/article/details/106933974" target="_blank" rel="noopener">命名实体识别学习-从基础算法开始（02）lstm+crf序列标注</a> 里介绍过。</p>
<p>预处理思路：获取每句话的tokens数组和tags数组，其中每句话用一个空行分隔。</p>
<p>根据上面思路，处理起来很简单：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Conll03Reader</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read</span><span class="params">(self, data_path)</span>:</span></span><br><span class="line">        data_parts = [<span class="string">'train'</span>, <span class="string">'valid'</span>, <span class="string">'test'</span>]</span><br><span class="line">        extension = <span class="string">'.txt'</span></span><br><span class="line">        dataset = &#123;&#125;</span><br><span class="line">        <span class="keyword">for</span> data_part <span class="keyword">in</span> tqdm(data_parts):</span><br><span class="line">            file_path = os.path.join(data_path, data_part+extension)</span><br><span class="line">            dataset[data_part] = self.read_file(str(file_path))</span><br><span class="line">        <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">read_file</span><span class="params">(self, file_path)</span>:</span></span><br><span class="line">        samples = []</span><br><span class="line">        tokens = []</span><br><span class="line">        tags = []</span><br><span class="line">        <span class="keyword">with</span> open(file_path,<span class="string">'r'</span>, encoding=<span class="string">'utf-8'</span>) <span class="keyword">as</span> fb:</span><br><span class="line">            <span class="keyword">for</span> line <span class="keyword">in</span> fb:</span><br><span class="line">                line = line.strip(<span class="string">'\n'</span>)</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> line == <span class="string">'-DOCSTART- -X- -X- O'</span>:</span><br><span class="line">                    <span class="comment"># 去除数据头</span></span><br><span class="line">                    <span class="keyword">pass</span></span><br><span class="line">                <span class="keyword">elif</span> line ==<span class="string">''</span>:</span><br><span class="line">                    <span class="comment"># 一句话结束</span></span><br><span class="line">                    <span class="keyword">if</span> len(tokens) != <span class="number">0</span>:</span><br><span class="line">                        samples.append((tokens, tags))</span><br><span class="line">                        tokens = []</span><br><span class="line">                        tags = []</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="comment"># 数据分割，只要开头的词和最后一个实体标注。</span></span><br><span class="line">                    contents = line.split(<span class="string">' '</span>)</span><br><span class="line">                    tokens.append(contents[<span class="number">0</span>])</span><br><span class="line">                    tags.append(contents[<span class="number">-1</span>])</span><br><span class="line">        <span class="keyword">return</span> samples</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    ds_rd = Conll03Reader()</span><br><span class="line">    data = ds_rd.read(<span class="string">"./conll2003_v2"</span>)</span><br><span class="line">    <span class="keyword">for</span> sample <span class="keyword">in</span> data[<span class="string">'train'</span>][:<span class="number">10</span>]:</span><br><span class="line">        print(sample)</span><br></pre></td></tr></table></figure>

<h2 id="四-总结"><a href="#四-总结" class="headerlink" title="四 总结"></a>四 总结</h2><p>将数据集处理为模型可读的标准化输入是整个模型的第一步，接下来文章将尝试用模型处理该数据集，并介绍一种可通用的数据处理的pipeline。</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/07/05/面试中常见的图论问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wei">
      <meta itemprop="description" content="有志者，事竟成">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SStarLib's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/07/05/面试中常见的图论问题/" class="post-title-link" itemprop="url">面试中常见的图论问题</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2020-07-05 21:41:13" itemprop="dateCreated datePublished" datetime="2020-07-05T21:41:13+08:00">2020-07-05</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-07-12 15:14:01" itemprop="dateModified" datetime="2020-07-12T15:14:01+08:00">2020-07-12</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="面试中常见的图论问题"><a href="#面试中常见的图论问题" class="headerlink" title="面试中常见的图论问题"></a><center>面试中常见的图论问题</center></h1><p>[TOC]</p>
<h2 id="二分图问题："><a href="#二分图问题：" class="headerlink" title="二分图问题："></a>二分图问题：</h2><p><a href="https://leetcode.com/problems/is-graph-bipartite/" target="_blank" rel="noopener">LeetCode 785. Is Graph Bipartite?</a></p>
<p>这是一个直白的二分图问题：二分图问题，就是可否将图的所有节点分成两个集合，有连边两个点不在一个集合。</p>
<p>将二分图问题可以看成二染色问题，即使用两种颜色对图进行染色，相连的两个点，颜色不能相同。</p>
<p>解决办法：遍历染色</p>
<p>DFS+染色：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isBipartite</span><span class="params">(<span class="keyword">int</span>[][] graph)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 染色状态; 0-未染色，1-蓝色，-1-红色</span></span><br><span class="line">        <span class="keyword">int</span>[] colors = <span class="keyword">new</span> <span class="keyword">int</span>[graph.length];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; colors.length; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span>(colors[i]==<span class="number">0</span> &amp;&amp; !dfs(i, <span class="number">1</span>, colors, graph))&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> v, <span class="keyword">int</span> color, <span class="keyword">int</span>[] colors, <span class="keyword">int</span>[][] graph)</span> </span>&#123;</span><br><span class="line">        colors[v]=color;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> adjV:graph[v])&#123;</span><br><span class="line">            <span class="keyword">if</span>(colors[adjV]==color) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">if</span>(colors[adjV]==<span class="number">0</span> &amp;&amp; !dfs(adjV, -color, colors, graph))&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>也可以BFS+染色：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isBipartite</span><span class="params">(<span class="keyword">int</span>[][] graph)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 染色状态; 0-未染色，1-蓝色，-1-红色</span></span><br><span class="line">        <span class="keyword">int</span>[] colors = <span class="keyword">new</span> <span class="keyword">int</span>[graph.length];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; colors.length; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span>(colors[i]==<span class="number">0</span> &amp;&amp; graph[i].length&gt;<span class="number">0</span>)&#123;</span><br><span class="line">                colors[i] = <span class="number">1</span>;</span><br><span class="line">                Queue&lt;Integer&gt; q = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">                q.offer(i);</span><br><span class="line">                <span class="keyword">while</span>(!q.isEmpty())&#123;</span><br><span class="line">                    <span class="keyword">int</span> curr = q.poll();</span><br><span class="line">                    <span class="keyword">for</span>(<span class="keyword">int</span> adjV:graph[curr])&#123;</span><br><span class="line">                        <span class="keyword">if</span>(colors[adjV]==<span class="number">0</span>)&#123;</span><br><span class="line">                            colors[adjV]=-colors[curr];</span><br><span class="line">                            q.offer(adjV);</span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">else</span> <span class="keyword">if</span>(colors[adjV]==colors[curr]) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a href="https://leetcode.com/problems/possible-bipartition/" target="_blank" rel="noopener">886. Possible Bipartition</a></p>
<p>这道题加了点丰富的背景，但是很容易看出来还是一个二分图问题。据说这道题是今年字节跳动的笔试题</p>
<p>多了一点构建图。</p>
<p>DFS+染色：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">possibleBipartition</span><span class="params">(<span class="keyword">int</span> N, <span class="keyword">int</span>[][] dislikes)</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 构建图</span></span><br><span class="line">        List&lt;Integer&gt;[] graph = <span class="keyword">new</span> ArrayList[N+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; N+<span class="number">1</span>; i++) &#123;</span><br><span class="line">            graph[i] = <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span>[] l : dislikes) &#123;</span><br><span class="line">            graph[l[<span class="number">0</span>]].add(l[<span class="number">1</span>]);</span><br><span class="line">            graph[l[<span class="number">1</span>]].add(l[<span class="number">0</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 状态数组</span></span><br><span class="line">        <span class="keyword">int</span>[] colors = <span class="keyword">new</span> <span class="keyword">int</span>[N+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; N+<span class="number">1</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span>(colors[i]==<span class="number">0</span> &amp;&amp; !dfs(i, graph, colors, <span class="number">1</span>))&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> pid, List&lt;Integer&gt;[] graph, <span class="keyword">int</span>[] colors, <span class="keyword">int</span> color)</span></span>&#123;</span><br><span class="line">        colors[pid] = color;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> other_pid : graph[pid]) &#123;</span><br><span class="line">            <span class="keyword">if</span>(colors[other_pid]==color) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            <span class="keyword">if</span>(colors[other_pid]==<span class="number">0</span> &amp;&amp; !dfs(other_pid, graph, colors, -color))&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="拓扑排序问题"><a href="#拓扑排序问题" class="headerlink" title="拓扑排序问题"></a>拓扑排序问题</h2><p>详细介绍见我这篇博客：<a href="https://blog.csdn.net/StarLib/article/details/105126754" target="_blank" rel="noopener">BFS DFS 判断DAG(有向无环图)</a></p>
<p><a href="https://leetcode.com/problems/course-schedule/" target="_blank" rel="noopener">207. Course Schedule</a></p>
<p>这道题原先用Python写过。BFS+入度，和DFS暴力搜索两种，直接上java代码；</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">    public boolean canFinish(int numCourses, int[][] prerequisites) &#123;</span><br><span class="line">        //邻接表建图</span><br><span class="line">        ArrayList&lt;Integer&gt;[] graph = new ArrayList[numCourses];</span><br><span class="line">        //记录每个节点的入度</span><br><span class="line">        int[] indegree = new int[numCourses];</span><br><span class="line">        <span class="keyword">for</span> (int i = <span class="number">0</span>; i &lt; numCourses; i++) &#123;</span><br><span class="line">            graph[i]=new ArrayList&lt;&gt;();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(int[] prq:prerequisites)&#123;</span><br><span class="line">            // 需要先修的课程指向后修的课程</span><br><span class="line">            graph[prq[<span class="number">1</span>]].add(prq[<span class="number">0</span>]);</span><br><span class="line">            // 后修的课程入度+<span class="number">1</span>；</span><br><span class="line">            indegree[prq[<span class="number">0</span>]]++;</span><br><span class="line">        &#125;</span><br><span class="line">        // BFS 拓扑排序</span><br><span class="line">        Queue&lt;Integer&gt; q = new LinkedList&lt;&gt;();</span><br><span class="line">        int cnt=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (int i = <span class="number">0</span>; i &lt; numCourses; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span>(indegree[i]==<span class="number">0</span>)&#123;</span><br><span class="line">                q.offer(i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(!q.isEmpty())&#123;</span><br><span class="line">            int curr = q.poll();</span><br><span class="line">            cnt++;</span><br><span class="line">            <span class="keyword">for</span>(int adjV:graph[curr])&#123;</span><br><span class="line">                indegree[adjV]--;</span><br><span class="line">                <span class="keyword">if</span>(indegree[adjV]==<span class="number">0</span>) q.offer(adjV);</span><br><span class="line">            &#125;        </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> cnt==numCourses;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">canFinish</span><span class="params">(<span class="keyword">int</span> numCourses, <span class="keyword">int</span>[][] prerequisites)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//邻接表建图</span></span><br><span class="line">        ArrayList&lt;Integer&gt;[] graph = <span class="keyword">new</span> ArrayList[numCourses];</span><br><span class="line">        <span class="comment">// 状态数组</span></span><br><span class="line">        <span class="keyword">int</span>[] mark = <span class="keyword">new</span> <span class="keyword">int</span>[numCourses];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numCourses; i++) &#123;</span><br><span class="line">            graph[i]=<span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span>[] prq:prerequisites)&#123;</span><br><span class="line">            <span class="comment">// 需要先修的课程指向后修的课程</span></span><br><span class="line">            graph[prq[<span class="number">1</span>]].add(prq[<span class="number">0</span>]);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numCourses; i++) &#123;</span><br><span class="line">            <span class="keyword">if</span>(!dfs(i, mark, graph)) <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> v, <span class="keyword">int</span>[] mark, ArrayList&lt;Integer&gt;[] graph)</span> </span>&#123;</span><br><span class="line">        mark[v]=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> adjV:graph[v])&#123;</span><br><span class="line">            <span class="keyword">if</span>(mark[adjV]==<span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(!dfs(adjV, mark, graph)) </span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(mark[adjV]==<span class="number">1</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        mark[v]=<span class="number">2</span>;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a href="https://leetcode.com/problems/course-schedule-ii/" target="_blank" rel="noopener">210. Course Schedule II</a></p>
<p>这道拓扑排序，唯一的不同就是讲排序结果输出，用BFS+入度，再加个数组。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] findOrder(<span class="keyword">int</span> numCourses, <span class="keyword">int</span>[][] prerequisites) &#123;</span><br><span class="line">        <span class="keyword">int</span>[] res = <span class="keyword">new</span> <span class="keyword">int</span>[numCourses];</span><br><span class="line">        <span class="comment">// 建图，</span></span><br><span class="line">        ArrayList&lt;Integer&gt;[] graph = <span class="keyword">new</span> ArrayList[numCourses];</span><br><span class="line">        <span class="keyword">int</span>[] indegree = <span class="keyword">new</span> <span class="keyword">int</span>[numCourses];</span><br><span class="line">        <span class="keyword">int</span> cnt = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numCourses; i++) &#123;</span><br><span class="line">            graph[i]=<span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span>[] p: prerequisites)&#123;</span><br><span class="line">            graph[p[<span class="number">1</span>]].add(p[<span class="number">0</span>]);</span><br><span class="line">            indegree[p[<span class="number">0</span>]]++;</span><br><span class="line">        &#125;</span><br><span class="line">        Queue&lt;Integer&gt; q = <span class="keyword">new</span> LinkedList&lt;&gt;();</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;numCourses; i++)&#123;</span><br><span class="line">            <span class="keyword">if</span>(indegree[i]==<span class="number">0</span>)&#123;</span><br><span class="line">                q.offer(i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">while</span>(!q.isEmpty())&#123;</span><br><span class="line">            <span class="keyword">int</span> cur = q.poll();</span><br><span class="line">            res[cnt++] = cur;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> adjV: graph[cur])&#123;</span><br><span class="line">                indegree[adjV]--;</span><br><span class="line">                <span class="keyword">if</span>(indegree[adjV]==<span class="number">0</span>)</span><br><span class="line">                    q.offer(adjV);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> cnt==numCourses?res:<span class="keyword">new</span> <span class="keyword">int</span>[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="并查集检查冗余"><a href="#并查集检查冗余" class="headerlink" title="并查集检查冗余"></a>并查集检查冗余</h2><p>并查集详细介绍：<a href="https://blog.csdn.net/StarLib/article/details/106108198" target="_blank" rel="noopener">并查集原理及联通分量个数问题</a></p>
<blockquote>
<p>注：并查集上的点至少有两个属性：（data, parent),其中指向parent，这种映射关系，完全可以用数组的index-value代替，故我们可以有两个数组 parent，rank(用于UF的优化，路径压缩等等),而data作为index存在，映射关系则用数组实现。</p>
</blockquote>
<p><a href="https://leetcode.com/problems/redundant-connection/" target="_blank" rel="noopener">684. Redundant Connection</a></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">UF</span></span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span>[] parent;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span>[] rank;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">UF</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">            parent = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">            rank = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;</span><br><span class="line">                parent[i] = i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">find</span><span class="params">(<span class="keyword">int</span> p)</span></span>&#123;</span><br><span class="line">            <span class="comment">// 查找集合根节点</span></span><br><span class="line">            <span class="keyword">int</span> r = p;</span><br><span class="line">            <span class="keyword">while</span>(r!=parent[r])&#123;</span><br><span class="line">                r = parent[r];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 路径压缩</span></span><br><span class="line">            <span class="keyword">int</span> k = p;</span><br><span class="line">            <span class="keyword">while</span>(k!=r)&#123;</span><br><span class="line">                <span class="keyword">int</span> par = parent[k];</span><br><span class="line">                parent[k] = r;</span><br><span class="line">                k = par;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> r;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">union</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">int</span> rootp = find(p);</span><br><span class="line">            <span class="keyword">int</span> rootq = find(q);</span><br><span class="line">            <span class="keyword">if</span> (rootp==rootq) <span class="keyword">return</span>;</span><br><span class="line">            <span class="keyword">if</span>(rank[rootp]&gt;=rank[rootq])&#123;</span><br><span class="line">                <span class="keyword">if</span>(rank[rootp]==rank[rootq])&#123;</span><br><span class="line">                    rank[rootp]+=<span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                parent[rootq]=rootp;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                parent[rootp]=rootq;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">connect</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span></span>&#123;</span><br><span class="line">            <span class="keyword">return</span> find(p)==find(q);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">int</span>[] findRedundantConnection(<span class="keyword">int</span>[][] edges) &#123;</span><br><span class="line">        UF uf = <span class="keyword">new</span> UF(edges.length+<span class="number">1</span>);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span>[] edg:edges)&#123;</span><br><span class="line">            <span class="keyword">int</span> p=edg[<span class="number">0</span>],q=edg[<span class="number">1</span>];</span><br><span class="line">            <span class="keyword">if</span>(uf.connect(p, q))&#123;</span><br><span class="line">                <span class="keyword">return</span> edg;</span><br><span class="line">            &#125;</span><br><span class="line">            uf.union(p, q);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="keyword">int</span>[]&#123;-<span class="number">1</span>, -<span class="number">1</span>&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><a href="https://leetcode.com/problems/friend-circles/" target="_blank" rel="noopener">547. Friend Circles</a></p>
<p>单纯的并查集问题</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span></span>&#123;</span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">UnionFind</span></span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span> numSets = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">int</span>[] parent, rank;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">UnionFind</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line">            numSets = n;</span><br><span class="line">            parent = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">            rank = <span class="keyword">new</span> <span class="keyword">int</span>[n];</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;n; i++)&#123;</span><br><span class="line">                parent[i]=i;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">find</span><span class="params">(<span class="keyword">int</span> p)</span></span>&#123;</span><br><span class="line">            <span class="keyword">int</span> r = p;</span><br><span class="line">            <span class="keyword">while</span>(r!=parent[r])&#123;</span><br><span class="line">                r = parent[r];</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">int</span> k = p;</span><br><span class="line">            <span class="keyword">while</span>(k!=r)&#123;</span><br><span class="line">                <span class="keyword">int</span> j = parent[k];</span><br><span class="line">                parent[k]=r;</span><br><span class="line">                k = j;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> r;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">union</span><span class="params">(<span class="keyword">int</span> p, <span class="keyword">int</span> q)</span></span>&#123;</span><br><span class="line">            <span class="keyword">int</span> rootP = find(p);</span><br><span class="line">            <span class="keyword">int</span> rootQ = find(q);</span><br><span class="line">            <span class="keyword">if</span> (rootP==rootQ) <span class="keyword">return</span>;</span><br><span class="line">            <span class="keyword">if</span> (rank[rootP]&gt;=rank[rootQ])&#123;</span><br><span class="line">                <span class="keyword">if</span> (rank[rootP]==rank[rootQ])&#123;</span><br><span class="line">                    rank[rootP]+=<span class="number">1</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                parent[rootQ]=rootP;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                parent[rootP]=rootQ;</span><br><span class="line">            &#125;</span><br><span class="line">            numSets-=<span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getNumSets</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> numSets;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">findCircleNum</span><span class="params">(<span class="keyword">int</span>[][] M)</span> </span>&#123;</span><br><span class="line">        UnionFind uf = <span class="keyword">new</span> UnionFind(M.length);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;M.length;i++)&#123;</span><br><span class="line">            <span class="keyword">for</span>(<span class="keyword">int</span> j=i+<span class="number">1</span>; j&lt;M.length;j++)&#123;</span><br><span class="line">                <span class="keyword">if</span>(M[i][j]==<span class="number">1</span>) uf.union(i, j);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> uf.getNumSets();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>图论还有最短路问题，网络流问题（这个面试应该不会问）等等。以后遇到了接着补充</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/22/命名实体识别学习-从基础算法开始（02）lstm-crf序列标注/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wei">
      <meta itemprop="description" content="有志者，事竟成">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SStarLib's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/06/22/命名实体识别学习-从基础算法开始（02）lstm-crf序列标注/" class="post-title-link" itemprop="url">命名实体识别学习-从基础算法开始（02）lstm+crf序列标注</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2020-06-22 21:23:07" itemprop="dateCreated datePublished" datetime="2020-06-22T21:23:07+08:00">2020-06-22</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-06-23 23:04:45" itemprop="dateModified" datetime="2020-06-23T23:04:45+08:00">2020-06-23</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="命名实体识别学习-从基础算法开始（02）lstm-crf序列标注"><a href="#命名实体识别学习-从基础算法开始（02）lstm-crf序列标注" class="headerlink" title="命名实体识别学习-从基础算法开始（02）lstm+crf序列标注"></a><center>命名实体识别学习-从基础算法开始（02）lstm+crf序列标注</center></h1><p>[TOC]</p>
<p>代码地址：<a href="https://github.com/SStarLib/NERfromBasic" target="_blank" rel="noopener">https://github.com/SStarLib/NERfromBasic</a></p>
<h2 id="序列标注"><a href="#序列标注" class="headerlink" title="序列标注"></a>序列标注</h2><p>将命名实体识别看作序列标注问题，则可以用词性标注的方法来做。</p>
<p>标注方法：<a href="https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)" target="_blank" rel="noopener">Inside–outside–beginning (tagging)</a></p>
<h3 id="LSTM的不足"><a href="#LSTM的不足" class="headerlink" title="LSTM的不足"></a>LSTM的不足</h3><p><strong>序列标注问题，lstm就可以做，但是lstm生成的标注序列是无约束的。而CRFs可以给模型增加约束，以下面例子为例，单纯的lstm极有可能生成第二个非法序列（没有先出现B，就出现了I），而条件随机场可以从训练数据中学习约束</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">合法序列：</span><br><span class="line">&quot;the wall street journal reported today that apple corporation made money&quot;</span><br><span class="line">&quot; B   I      I      I       O       O     O    B        I       O     O&quot;</span><br><span class="line"></span><br><span class="line">非法序列：</span><br><span class="line">&quot;the wall street journal reported today that apple corporation made money&quot;</span><br><span class="line">&quot; I   I      I      I       O       O     O    B        I       O     O&quot;</span><br></pre></td></tr></table></figure>

<p><strong>条件随机场(CRFs)</strong>:</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gg1e3e8j80j30fh0bpac6.jpg" alt="image-20200622213107290"></p>
<p><strong>概率图模型：</strong></p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gg1e7xoc1nj30fi0blad0.jpg" alt="image-20200622213529664"></p>
<p><strong>隐马尔可夫模型和条件随机场的区别：</strong>在CRFs中，观察序列X并不是由模型生成的。标记序列取值以观察序列为条件，同时来自于其邻接点。</p>
<h3 id="从CRFs模型推到代码实现"><a href="#从CRFs模型推到代码实现" class="headerlink" title="从CRFs模型推到代码实现"></a>从CRFs模型推到代码实现</h3><p>模型要解决序列标注问题。所以主要使用的是线性链式的CRFs。</p>
<p>李航老师在《统计学习方法》里的定义：</p>
<p>条件随机场(conditional random field)是给定随机变量X条件下，随机变量Y的马尔可夫随机场。其中线性链条件随机场可以用于标注等问题。这时， 在条件概率模型$\hat{P}(Y|X)$中，Y是输出变量，表示标记序列，X是输入变量，表示需要标注的观测序列。也把标记序列称为状态序列(参见隐马尔可夫模型)。学习时，利用训练数据集通过极大似然估计或正则化的极大似然估计得到条件概率模型 $\hat{P}(y|x)$;预测时，对于给定的输入序列$x$，求出条件概率 $\hat{P}(y|x)$最大的输出序列 。</p>
<p>线性链条件随机场参数化形式如：<br>$$<br>P(y | x) = \frac{1}{Z(x)}exp\bigg(<br>        \sum_{i,k}\lambda_k t_k (y_{i-1}, y_i, x, i)<br>                            +<br>        \sum_{i,l}\mu_l s_l (y_i, x, i)<br>                                \bigg)  \<br>    Z(x) = \sum_{y}exp\bigg(<br>        \sum_{i,k}\lambda_k t_k (y_{i-1}, y_i, x, i)<br>                            +<br>        \sum_{i,l}\mu_l s_l (y_i, x, i)<br>                                \bigg)  \<br>$$<br>可以使用梯度下降的方法对CRF参数进行梯度学习。（这里跟HMM模型很像），同时需要用前向算法递归的计算概率及期望值。前向算法本质是动态规划算法，基本思想L：定义前向变量 $\alpha_t(i)$，递推式：<br>$$<br>\alpha_t(i)=p(O_1 O_2 \cdots O_t, q_t=S_i | \mu)<br>$$</p>
<p>在时间$t+1$的前向变量可以根据时间$t$的前向变量$\alpha_t(1),\cdots \alpha_t(N)$的值递推计算,前向算法如下：</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gg2lotaij6j30ou0auwfq.jpg" alt="image-20200623223927451"></p>
<p>前向算法，可以求出对应的概率，不但可以计算出预测标签的概率，同时可以计算真实标签的概率。然后应用损失函数，梯度下降的思想，可以逐渐优化LSTM的参数和CRF的参数。但是将CRF真正应用到LSTM的顶层，还需要做一些相应的变换，至少应该以训练网络的思想。已知句子序列$X$, 用前向算法判断标注序列的得分<br>$$<br>P_X(y_1,y_2,\cdots,y_T)\<br>        =P_X(y_1) P_X(y_2|y_1) P_X(y_3|y_2) \cdots P_X(y_T|y_{T-1})\<br>        =P_X(y_1) \frac{P_X(y_1, y_2)}{P_X(y_1) P_X(y_2)} P_X(y_2) \frac{P_X(y_2, y_3)}{P_X(y_2) P_X(y_3)}P_X(y_3) \dots \frac{P_X(y_{T-1}, y_T)}{P_X(y_{T-1}) P_X(y_T)} P_X(y_T)<br>$$</p>
<p>以$P_X(y_1, y_2)$为例，即在观察序列X下，在i=1位置标注记为$y_1$,在i=2位置标注记为$y_2$的概率。从序列标注的角度和CRF的定义出发，我们可以分解这个概率，即在i=1位置标注为$y_1$的概率$P_X(y_1)$, 假设L为标签集合，$y_1=l_i,y_2=l_j$,$i,j \in L$,则有转移概率$P(l_i-&gt;l_j)$,然后是$P_X (y_2)$ 即在观察序列X下，在i=2位置标注记为$y_2$的概率。然后可以在对数空间去看这个公式，并舍弃概率的意义。<br>$$<br>P_X(y_1,y_2,\cdots,y_T) \<br>        = \frac{1}{Z} \exp \Big[emit(y_1;X)+<br>        trans(y_1, y_2;X) + emit(y_2;X)<br>         +\cdots + trans(y_{T-1}, y_T;X) + emit(y_T;X) \Big]<br>$$<br>定义函数 $ emit(y_i ; X) $ 为在观察序列X下，i位置标记为$y_i$的分数。定义函数$ trans(y_i, y_j ; X) $为在观察序列X下,$y_i$标记转移到$y_j$的分。对等式整理得如下所示：<br>$$<br>\log{P} = \sum_{i=1}^T emit(y_i) + \sum_{i=1}^{T-1} trans(y_i,y_{i+1}) + \log{Z}<br>$$<br>用前向算法的思想实现以上等式,整理递推表达式:<br>$$<br>foward_{i+1} = forward_{i} + emit(i) + trans(y_i, y_{i+1})<br>$$<br>用Python语言实现该前向算法:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_forward_alg</span><span class="params">(self, feats)</span>:</span></span><br><span class="line">        init_alphas = torch.full((<span class="number">1</span>, self.tagset_size), <span class="number">-10000.</span>).to(device)</span><br><span class="line">        init_alphas[<span class="number">0</span>][self.tag_to_ix[START_TAG]] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        forward_var = init_alphas</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Iterate through the sentence</span></span><br><span class="line">        <span class="keyword">for</span> feat <span class="keyword">in</span> feats:</span><br><span class="line">            alphas_t = [] <span class="comment"># The forward tensors at this timestep 前向张量</span></span><br><span class="line">            <span class="keyword">for</span> next_tag <span class="keyword">in</span> range(self.tagset_size):</span><br><span class="line">                emit_score = feat[next_tag].view(<span class="number">1</span>, <span class="number">-1</span>).expand(<span class="number">1</span>, self.tagset_size)</span><br><span class="line">                trans_score = self.transitions[next_tag].view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">                next_tag_var = forward_var + trans_score + emit_score</span><br><span class="line">                alphas_t.append(log_sum_exp(next_tag_var).view(<span class="number">1</span>))</span><br><span class="line">            forward_var = torch.cat(alphas_t).view(<span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]</span><br><span class="line">        alpha = log_sum_exp(terminal_var)</span><br><span class="line">        <span class="keyword">return</span> alpha</span><br></pre></td></tr></table></figure>

<h4 id="设计损失函数"><a href="#设计损失函数" class="headerlink" title="设计损失函数"></a>设计损失函数</h4><p>有了前向算法，就可以设计损失函数， 由于训练的目的是为了学习到更准确的发射矩阵(emit score matrix)和转移矩阵(trans score matrix)，可以将真实标注输入前向算法得到一个分数，以及预测标注输入前向算法得到一个分数，以这两个分数的差值作为损失函数。这不只是经验上的选择，已有文献进行了数学上的证明，就不再赘述。损失函数的实现代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_score_sentence</span><span class="params">(self, feats, tags)</span>:</span></span><br><span class="line">        score = torch.zeros(<span class="number">1</span>).to(device)</span><br><span class="line">        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags]).to(device)</span><br><span class="line">        <span class="keyword">for</span> i, feat <span class="keyword">in</span> enumerate(feats):</span><br><span class="line">            score = score + self.transitions[ tags[i + <span class="number">1</span>], tags[i] ] + feat[ tags[i + <span class="number">1</span>] ]</span><br><span class="line">        score = score + self.transitions[ self.tag_to_ix[STOP_TAG], tags[<span class="number">-1</span>] ]</span><br><span class="line">        <span class="keyword">return</span> score</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">neg_log_likelihood</span><span class="params">(self, sentence, tags)</span>:</span></span><br><span class="line">        feats = self._get_lstm_features(sentence)</span><br><span class="line">        forward_score = self._forward_alg(feats)</span><br><span class="line">        gold_score = self._score_sentence(feats, tags)</span><br><span class="line">        <span class="keyword">return</span> forward_score - gold_score</span><br></pre></td></tr></table></figure>

<h3 id="LSTM提取特征"><a href="#LSTM提取特征" class="headerlink" title="LSTM提取特征"></a>LSTM提取特征</h3><p>代码: lstm的参数就是emit score 即，对于观察序列，给每个可能的标注打分。这是个矩阵，可以用反向传播进行学习。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_lstm_features</span><span class="params">(self, sentence)</span>:</span></span><br><span class="line">    self.hidden = self.init_hidden()</span><br><span class="line">    embeds = self.word_embeds(sentence).view(len(sentence), <span class="number">1</span>, <span class="number">-1</span>)</span><br><span class="line">    lstm_out, self.hidden = self.lstm(embeds, self.hidden)</span><br><span class="line">    lstm_out = lstm_out.view(len(sentence), self.hidden_dim)</span><br><span class="line">    lstm_feats = self.hidden2tag(lstm_out)</span><br><span class="line">    <span class="keyword">return</span> lstm_feats</span><br></pre></td></tr></table></figure>

<h3 id="模型整体框架"><a href="#模型整体框架" class="headerlink" title="模型整体框架"></a>模型整体框架</h3><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gg2m60hq12j30rw0es40f.jpg" alt="image-20200623225600435"></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>lstm学习emit score，crf优化trans score，前向算法+neg-log-sum 进行计算loss，维特比算法解码出标记序列在新样本上进行推断。</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/22/命名实体识别学习-从基础算法开始-维特比算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wei">
      <meta itemprop="description" content="有志者，事竟成">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SStarLib's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/06/22/命名实体识别学习-从基础算法开始-维特比算法/" class="post-title-link" itemprop="url">命名实体识别学习-从基础算法开始-维特比算法</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2020-06-22 15:28:49 / Modified: 16:30:51" itemprop="dateCreated datePublished" datetime="2020-06-22T15:28:49+08:00">2020-06-22</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="命名实体识别学习-从基础算法开始（01）-维特比算法"><a href="#命名实体识别学习-从基础算法开始（01）-维特比算法" class="headerlink" title="命名实体识别学习-从基础算法开始（01）-维特比算法"></a><center>命名实体识别学习-从基础算法开始（01）-维特比算法</center></h1><p>[TOC]</p>
<p><strong>代码地址：</strong><a href="https://github.com/SStarLib/NERfromBasic" target="_blank" rel="noopener">https://github.com/SStarLib/NERfromBasic</a></p>
<h2 id="Day1-维特比算法"><a href="#Day1-维特比算法" class="headerlink" title="Day1: 维特比算法"></a>Day1: 维特比算法</h2><h3 id="HMM的小例子"><a href="#HMM的小例子" class="headerlink" title="HMM的小例子"></a>HMM的小例子</h3><p>从一个小例子开始实现维特比算法：</p>
<p>例子来自知乎一个答案对维特比算法和HMM的讲解：</p>
<p>如何通俗地讲解 viterbi 算法？ - Kiwee的回答 - 知乎<br><a href="https://www.zhihu.com/question/20136144/answer/239971177" target="_blank" rel="noopener">https://www.zhihu.com/question/20136144/answer/239971177</a></p>
<p>大致介绍下这个例子：</p>
<h4 id="题目背景"><a href="#题目背景" class="headerlink" title="题目背景"></a>题目背景</h4><blockquote>
<p>从前有个村儿，村里的人的身体情况只有两种可能：健康或者发烧。<br>假设这个村儿的人没有体温计或者百度这种神奇东西，他唯一判断他身体情况的途径就是到村头我的偶像金正月的小诊所询问。<br>月儿通过询问村民的感觉，判断她的病情，再假设村民只会回答正常、头晕或冷。<br>有一天村里奥巴驴就去月儿那去询问了。<br>第一天她告诉月儿她感觉正常。<br>第二天她告诉月儿感觉有点冷。<br>第三天她告诉月儿感觉有点头晕。<br>那么问题来了，月儿如何根据阿驴的描述的情况，推断出这三天中阿驴的一个身体状态呢?</p>
</blockquote>
<h4 id="将问题抽象为一个HMM"><a href="#将问题抽象为一个HMM" class="headerlink" title="将问题抽象为一个HMM"></a>将问题抽象为一个HMM</h4><p>从问题中过可以看出，{健康，发烧}对应隐马尔可夫模型中的状态序列，{正常，冷，头晕}，则对应观察序列。（本例子其实不严谨，冷，头晕这两个观察现象是可以同时存在的，不过本例中假设其不同时存在）</p>
<p><strong>问题要求</strong>：推断出这三天中阿驴的一个身体状态</p>
<p><strong>问题本质</strong>：解码这三天的状态序列。</p>
<p><strong>模型参数</strong>：状态转移概率矩阵，状态-观察概率分布矩阵，初始状态</p>
<ul>
<li><p><strong>初始状态：</strong>月儿预判的阿驴身体状态的概率分布 = { 健康：0.6 , 发烧： 0.4 }</p>
</li>
<li><p><strong>状态转移概率矩阵</strong>： {<br>健康-&gt;健康： 0.7 ,<br>健康-&gt;发烧： 0.3 ,<br>发烧-&gt;健康：0.4 ,<br>发烧-&gt;发烧： 0.6<br>}</p>
</li>
<li><p><strong>状态-观察概率分布矩阵：</strong>{<br>健康，正常：0.5 ，冷 ：0.4 ，头晕： 0.1 ；<br>发烧，正常：0.1 ，冷 ：0.3 ，头晕： 0.6<br>}</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gg14m581ftj30u00wpkjl.jpg" alt="image-20200622160308608"></p>
</li>
</ul>
<p>有了模型参数。就可以构建模型并用维特比算法进行解码了即预测三天的身体状态。</p>
<h3 id="Python实现维特比算法"><a href="#Python实现维特比算法" class="headerlink" title="Python实现维特比算法"></a>Python实现维特比算法</h3><p>为了方便后面学习，使用Pytorch框架（其实numpy应该更简单些）</p>
<h4 id="手算维特比过程："><a href="#手算维特比过程：" class="headerlink" title="手算维特比过程："></a>手算维特比过程：</h4><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gg14f4ex59j316v0u0qv5.jpg" alt="image-20200622155623835"></p>
<h4 id="伪代码："><a href="#伪代码：" class="headerlink" title="伪代码："></a>伪代码：</h4><p><strong>维特比算法的伪代码（来自宗成庆老师的ppt）：</strong></p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gg152uso7sj30u018j7wi.jpg" alt="image-20200622161813184"></p>
<h4 id="代码前期准备"><a href="#代码前期准备" class="headerlink" title="代码前期准备"></a>代码前期准备</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    states = [ <span class="string">"健康"</span>, <span class="string">"发烧"</span>]</span><br><span class="line">    observations = [<span class="string">"正常"</span>,<span class="string">"冷"</span>, <span class="string">"头晕"</span>]</span><br><span class="line">    tran_matrix = torch.Tensor([[<span class="number">0.7</span>, <span class="number">0.3</span>], [<span class="number">0.4</span>, <span class="number">0.6</span>]]) <span class="comment">#A_ij</span></span><br><span class="line">    emit_matrix = torch.Tensor([[<span class="number">0.5</span>, <span class="number">0.4</span>, <span class="number">0.1</span>], [<span class="number">0.1</span>, <span class="number">0.3</span>, <span class="number">0.6</span>]])</span><br><span class="line">    init_state = [<span class="number">0.6</span>, <span class="number">0.4</span>]</span><br><span class="line">    observation_seq = [<span class="string">"正常"</span>,<span class="string">"冷"</span>, <span class="string">"头晕"</span>]</span><br><span class="line">    viterbi = Viterbi(toIdx(states), toIdx(observations), tran_matrix, emit_matrix)</span><br><span class="line">    maxpro, path = viterbi.viterbi(init_state, observation_seq)</span><br><span class="line">    print(<span class="string">"最大概率为：&#123;&#125;"</span>.format(maxpro))</span><br><span class="line">    print(<span class="string">"最大概率下路径为："</span>)</span><br><span class="line">    pt = <span class="string">""</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> path:</span><br><span class="line">        pt += states[i] + <span class="string">"-&gt;"</span></span><br><span class="line">    print(pt)</span><br><span class="line">main()</span><br></pre></td></tr></table></figure>

<p>将模型主要参数：有状态空间，观察空间，状态转移概率矩阵，状态-观察概率分布矩阵（发射矩阵），初始状态</p>
<p>输入：观察序列（代码里也将初始状态作为了输入了）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Viterbi</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,s_to_idx, v_to_idx, tran_matrix, emit_matrix)</span>:</span></span><br><span class="line">        self.s_to_idx = s_to_idx</span><br><span class="line">        self.v_to_idx = v_to_idx</span><br><span class="line">        self.tran_matrix = torch.Tensor(tran_matrix).transpose(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">        self.emit_matrix = torch.Tensor(emit_matrix).transpose(<span class="number">0</span>,<span class="number">1</span>)</span><br><span class="line">        self.state_size = len(s_to_idx)</span><br></pre></td></tr></table></figure>

<p>维特比算法本质是动态规划算法，具有最优子结构，需要确定初始量，和递推关系。</p>
<p><strong>小数的乘法计算会导致数越来越小，所以代码在对数空间上进行计算</strong></p>
<p>第一步计算初始维特比变量：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在对数空间初始化维特比变量</span></span><br><span class="line">      res = []</span><br><span class="line">      init_state=torch.Tensor(init_state)</span><br><span class="line">      <span class="keyword">for</span> i, s <span class="keyword">in</span> enumerate(init_state):</span><br><span class="line">          v = self.v_to_idx[v_seq[<span class="number">0</span>]]</span><br><span class="line">          tmp = torch.log(s)+torch.log(self.emit_matrix[v][i])</span><br><span class="line">          res.append(tmp)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">del</span> init_state</span><br><span class="line">      init_vvars = torch.stack(res)</span><br><span class="line"></span><br><span class="line">      forward_var = init_vvars</span><br></pre></td></tr></table></figure>

<p>第二步 迭代计算：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> v_seq[<span class="number">1</span>:]:</span><br><span class="line">    bptrs_t =[]</span><br><span class="line">    viterbivars_t = []</span><br><span class="line">    v_index = self.v_to_idx[v]</span><br><span class="line">    <span class="keyword">for</span> s <span class="keyword">in</span> range(self.state_size):</span><br><span class="line">        next_tag_var = forward_var+torch.log(self.tran_matrix[s])</span><br><span class="line">        best_tag_id = argmax(next_tag_var)</span><br><span class="line">        bptrs_t.append(best_tag_id)</span><br><span class="line">        viterbivars_t.append(next_tag_var[best_tag_id])</span><br><span class="line">    forward_var = (torch.Tensor(viterbivars_t)+torch.log(self.emit_matrix[v_index]))</span><br><span class="line">    backpointers.append(bptrs_t)</span><br><span class="line"><span class="comment"># 终结</span></span><br><span class="line">terminal_var = forward_var</span><br><span class="line">best_tag_id = argmax(terminal_var)</span><br><span class="line">path_score = terminal_var[best_tag_id]</span><br></pre></td></tr></table></figure>

<p>回溯解码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 回溯解码</span></span><br><span class="line">      best_path = [best_tag_id]</span><br><span class="line">      <span class="keyword">for</span> bptrs_t <span class="keyword">in</span> reversed(backpointers):</span><br><span class="line">          best_tag_id = bptrs_t[best_tag_id]</span><br><span class="line">          best_path.append(best_tag_id)</span><br><span class="line"></span><br><span class="line">      best_path.reverse()</span><br><span class="line">      <span class="keyword">return</span> torch.exp(path_score), best_path</span><br></pre></td></tr></table></figure>

<p>结果：</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">最大概率为：<span class="number">0.015120003372430801</span></span><br><span class="line">最大概率下路径为：</span><br><span class="line">健康-&gt;健康-&gt;发烧-&gt;</span><br></pre></td></tr></table></figure>

<p>结果和手算的一致</p>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>维特比算法本质就是动态规划代码。使用pytorch基本都是向量的运算。涉及到分数的连乘除最好转为对数的加减</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/16/Chinese-NER-Using-Lattice-LSTM-笔记/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wei">
      <meta itemprop="description" content="有志者，事竟成">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SStarLib's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/06/16/Chinese-NER-Using-Lattice-LSTM-笔记/" class="post-title-link" itemprop="url">Chinese NER Using Lattice LSTM -笔记</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2020-06-16 15:46:32 / Modified: 18:34:00" itemprop="dateCreated datePublished" datetime="2020-06-16T15:46:32+08:00">2020-06-16</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Chinese-NER-Using-Lattice-LSTM-笔记"><a href="#Chinese-NER-Using-Lattice-LSTM-笔记" class="headerlink" title="Chinese NER Using Lattice LSTM -笔记"></a><center>Chinese NER Using Lattice LSTM -笔记</center></h1><p>[TOC]</p>
<h2 id="简介："><a href="#简介：" class="headerlink" title="简介："></a>简介：</h2><p>论文题目：《Chinese NER Using Lattice LSTM》</p>
<p>论文链接：<a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1805.02023" target="_blank" rel="noopener">https://arxiv.org/abs/1805.02023</a></p>
<p>这是一篇发表在2018年自然语言处理领域顶级会议ACL的文章，提出了一种用于中文NER（命名实体识别）的Lattice LSTM模型。</p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>中文NER与分词有关。因为NEs(命名实体)是分词任务中OOV的重要来源。由于跨域分词（cross- domain word segmentation）仍然是一个未解决的问题。故在open domain 分词OOV更严重。</p>
<p>character-based方法优于word-based方法</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/14/NBSVM-算法学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wei">
      <meta itemprop="description" content="有志者，事竟成">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SStarLib's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/06/14/NBSVM-算法学习/" class="post-title-link" itemprop="url">NBSVM 算法学习</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2020-06-14 18:14:29" itemprop="dateCreated datePublished" datetime="2020-06-14T18:14:29+08:00">2020-06-14</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-06-15 12:41:40" itemprop="dateModified" datetime="2020-06-15T12:41:40+08:00">2020-06-15</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="NBSVM-Naive-Bayes-Support-Vector-Machine-学习"><a href="#NBSVM-Naive-Bayes-Support-Vector-Machine-学习" class="headerlink" title="NBSVM (Naive Bayes - Support Vector Machine)学习"></a>NBSVM (Naive Bayes - Support Vector Machine)学习</h1><p>[TOC]</p>
<h2 id="相关资料"><a href="#相关资料" class="headerlink" title="相关资料"></a>相关资料</h2><p> 论文：<a href="https://nlp.stanford.edu/pubs/sidaw12_simple_sentiment.pdf" target="_blank" rel="noopener">Baselines and Bigrams: Simple, Good Sentiment and Topic Classiﬁcation</a>.</p>
<p>fastai课程： <a href="https://youtu.be/37sFIak42Sc?t=3745" target="_blank" rel="noopener">Naive Bayes video</a>.</p>
<p>kaggle：<a href="https://www.kaggle.com/jhoward/nb-svm-strong-linear-baseline" target="_blank" rel="noopener">NB-SVM strong linear baseline</a></p>
<h2 id="Motivation"><a href="#Motivation" class="headerlink" title="Motivation"></a>Motivation</h2><p>NB(Naive Bayes)在短文本上表现好，SVM在长文本上表现好。(论文里的观点，实际可能未必！)</p>
<h2 id="NB-Naive-Bayes"><a href="#NB-Naive-Bayes" class="headerlink" title="NB(Naive Bayes)"></a>NB(Naive Bayes)</h2><p>贝叶斯公式（西瓜书里有比较有趣的介绍）。一些基本概念（ppt来自刘成林老师）：</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfs8inw4ocj30k50gp0vf.jpg" alt="image-20200614214846240"></p>
<p>举例说明，假如一个要判定一个comment是不是有毒(toxic), 如果看不到文本内容情况下，自然可以用抛硬币的模型则p(toxic=1)=0.5, 如果看到了内容里的一个单词，比如‘fxxk’，那么p(toxic=1｜word=‘fxxk’)的概率可能要远远大于0.5，而目标就是求这个后验概率p(w|x)，$P(w_i)$ 为类别为i的概率,贝叶斯公式：</p>
<p>$$p(w_i|x)= \frac{p(x|w_i)P(w_i)}{p(x)}$$</p>
<p>因为贝叶斯公式有理论指导，理论情况下是百分百准确的决策器，（主要看概率密度函数的估计，先验概率是否准确等。）但是一般情况下对条件概率的估计不会完全准确（本例中使用最大似然估计）</p>
<p>举例：</p>
<blockquote>
<p>包含某单词x，的toxic=1的文本为200个，toxic=1的文本总共为1000，那么就能用最大似然估计出p(x｜w=1)，估计出p(x|w=-1),</p>
</blockquote>
<h3 id="本论文中的贝叶斯："><a href="#本论文中的贝叶斯：" class="headerlink" title="本论文中的贝叶斯："></a>本论文中的贝叶斯：</h3><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfs4bmjw9sj30av01ejr8.jpg" alt="image-20200614210256663"></p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfs4ct6zsqj30az01h3yh.jpg" alt="image-20200614210401856"></p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfs4ccop1dj30b705jwex.jpg" alt="image-20200614210339659"></p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfs7kb2ndoj30bi05tq3l.jpg" alt="image-20200614225506214"></p>
<p>上式是该模型的主要公式，其中r将作为模型的权重，r为特征f在正性文本的比率比上f在负性文本的比率。</p>
<p>$r = \log \frac{\text{ratio of feature $f$ in positive comments}}{\text{ratio of feature $f$ in negative comments}}$</p>
<p><code>为了能够结合SVM，本文中的正负类用1, -1 表示。</code></p>
<h5 id="数据介绍："><a href="#数据介绍：" class="headerlink" title="数据介绍："></a>数据介绍：</h5><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfs4j04775j306n02vwec.jpg" alt="image-20200614211002446"></p>
<p>（159571, 426005）表示共有159571个评论，字典大小为426005。也即x是由159571个426005维的count vector 构成的矩阵。</p>
<blockquote>
<p>第一眼看论文部分,没太看懂哪里用了贝叶斯，假设train_i为159571个评论文本中的第i个, 对toxic这个label进行分类。特征维度为V(V=426005)，特征矩阵即矩阵x，维度为（159571, 426005）的矩阵表示词典里的每个词在每个文本中出现的次数。最大似然估计条件概率：p(x|y=1), p(x|y=-1), 对应代码为 <code>x[y==y_i].sum(0)</code>,y_i={0,1}, 这个维度为(1, 426005)表示每个特征出现在正/负文本中的文档数。求出包含某单词（特征）的正/负文本数，然后除以正/负文本的总个数，估计出 $p(x_j|w=0), p(x_j|w=1)$, j=1,…426005.其中$p(x_j|w=1)=p/||p||_1,  p(x_j|w=-1)=q/||q||_1$ 然后论文用这两个设计了一个新的特征，r， 并且用来作为线性模型的权重。（详细见论文）</p>
</blockquote>
<h4 id="r的解释："><a href="#r的解释：" class="headerlink" title="r的解释："></a>r的解释：</h4><p>如果r&gt;0,则表示该特征（该单词）更容易出现在正文本中，否则更容易出现在负文本中（结合线性模型比较符合经验判断。</p>
<h4 id="线性模型的解释"><a href="#线性模型的解释" class="headerlink" title="线性模型的解释"></a>线性模型的解释</h4><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfs4bmjw9sj30av01ejr8.jpg" alt="image-20200614210256663"></p>
<p>上图中的w=r,b为正负样本的数量比值，$x^{(k)}$为第k个case的特征向量。如果某个单词更容易出现在正样本中，则乘以一个正数的权重（这样的单词越多，文本越容易为正向），否则乘以负数的权重（这样的单词越多，越容易为负向）。b是现实正负样本的比值，总是偏向样本多的那个类别。</p>
<h4 id="维度情况："><a href="#维度情况：" class="headerlink" title="维度情况："></a>维度情况：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">x.shape</span><br><span class="line">(<span class="number">159571</span>, <span class="number">426005</span>)</span><br><span class="line"></span><br><span class="line">y = train[<span class="string">'toxic'</span>].values</span><br><span class="line">x[y==<span class="number">1</span>].shape</span><br><span class="line">(<span class="number">15294</span>, <span class="number">426005</span>)</span><br><span class="line"></span><br><span class="line">x[y==<span class="number">1</span>].sum(<span class="number">0</span>).shape</span><br><span class="line">(<span class="number">1</span>, <span class="number">426005</span>)</span><br><span class="line"></span><br><span class="line">(y==<span class="number">1</span>).shape</span><br><span class="line">(<span class="number">159571</span>,)</span><br><span class="line"></span><br><span class="line">(y==<span class="number">1</span>).sum()</span><br><span class="line"><span class="number">15294</span></span><br></pre></td></tr></table></figure>

<h2 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h2><p>将贝叶斯部分设计的特征作为输入。其他部分就是普通SVM模型。</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfs4thlj8kj30ba0ezdhu.jpg" alt="image-20200614212008887"></p>
<p>上面文章的最后一段也直接说明了：信任NB，除非SVM具有非常高的置信度。</p>
<h4 id="实现r和NBSVM的代码："><a href="#实现r和NBSVM的代码：" class="headerlink" title="实现r和NBSVM的代码："></a>实现r和NBSVM的代码：</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">pr</span><span class="params">(y_i, y)</span>:</span></span><br><span class="line">      print(y)</span><br><span class="line">      p = x[y==y_i].sum(<span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> (p+<span class="number">1</span>) / ((y==y_i).sum()+<span class="number">1</span>)</span><br><span class="line">     </span><br><span class="line">  x = trn_term_doc</span><br><span class="line">  test_x = test_term_doc</span><br><span class="line">  </span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">get_mdl</span><span class="params">(y)</span>:</span></span><br><span class="line">      y = y.values</span><br><span class="line">      r = np.log(pr(<span class="number">1</span>, y)/pr(<span class="number">0</span>, y))</span><br><span class="line">      m = LogisticRegression(C=<span class="number">4</span>, dual=<span class="literal">True</span> )</span><br><span class="line">      x_nb = x.multiply(r)</span><br><span class="line">      <span class="keyword">return</span> m.fit(x_nb, y), r</span><br><span class="line">      </span><br><span class="line">preds = np.zeros((len(test), len(label_cols)))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, j <span class="keyword">in</span> enumerate(label_cols):</span><br><span class="line">    print(<span class="string">'fit'</span>, j)</span><br><span class="line">    m,r = get_mdl(train[j])</span><br><span class="line">    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,<span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<p>SVM用的是sklearn中的LogisticRegression。x是tf-idf生成的文本稀疏矩阵。</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1gfs4j04775j306n02vwec.jpg" alt="image-20200614211002446"></p>
<p>（159571, 426005）表示共有159571个评论，字典大小为426005。也即x是由159571个426005维的count vector 构成的矩阵。</p>
<p>本任务中要预测多个label，16-21行代码是对多个label分别预测，模型是分开的。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>虽然论文里直说了</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/06/07/高楼扔鸡蛋-memorization-search/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wei">
      <meta itemprop="description" content="有志者，事竟成">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SStarLib's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/06/07/高楼扔鸡蛋-memorization-search/" class="post-title-link" itemprop="url">高楼扔鸡蛋-memorization search</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2020-06-07 21:51:12" itemprop="dateCreated datePublished" datetime="2020-06-07T21:51:12+08:00">2020-06-07</time>
            </span>
          

          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Edited on</span>
                
                <time title="Modified: 2020-06-08 11:30:12" itemprop="dateModified" datetime="2020-06-08T11:30:12+08:00">2020-06-08</time>
              </span>
            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="高楼扔鸡蛋-memorization-search"><a href="#高楼扔鸡蛋-memorization-search" class="headerlink" title="高楼扔鸡蛋-memorization search"></a><center>高楼扔鸡蛋-memorization search</center></h1><p>[TOC]</p>
<h2 id="题解"><a href="#题解" class="headerlink" title="题解:"></a>题解:</h2><p><a href="https://leetcode.com/problems/super-egg-drop/" target="_blank" rel="noopener">LeetCode 887. Super Egg Drop</a>.</p>
<p>这是一道经典的谷歌面试题，某公司今天的笔试题出了这道题（只不过扔的不是鸡蛋）。</p>
<h3 id="理解题意"><a href="#理解题意" class="headerlink" title="理解题意"></a>理解题意</h3><p>这道题是总共有N层楼，K个鸡蛋，找到鸡蛋摔破的极限楼层。最小需要尝试多少次，</p>
<p>(表示我第一次看到这道题，以为是一道数学题，并且还想眼巴巴的算出来。)</p>
<p>考虑状态转移，很容易想到动态规划。</p>
<p>假设从h楼摔下，如果摔碎，则状态变为：（K-1, h-1) （即K-1个鸡蛋，总共有h-1楼）</p>
<p>如果没摔碎，则状态变为：（K, N-h)</p>
<p>由此很容易写出递推式：</p>
<p>$$dp[k][n] = min(1+max(dp[k-1][i-1], dp[k][n-i]))  \ i=1…n $$</p>
<p>由递推式得到代码：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">superEggDrop</span><span class="params">(<span class="keyword">int</span> K, <span class="keyword">int</span> N)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[K+<span class="number">1</span>][N+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; K+<span class="number">1</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; N+<span class="number">1</span>; j++) &#123;</span><br><span class="line">                dp[i][j] = j;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">2</span>; i &lt; K+<span class="number">1</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; N+<span class="number">1</span>; j++) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> j2 = <span class="number">1</span>; j2 &lt; j; j2++) &#123;</span><br><span class="line">                    dp[i][j] = Math.min(dp[i][j], Math.max(dp[i-<span class="number">1</span>][j2-<span class="number">1</span>], dp[i][j-j2])+<span class="number">1</span>);   </span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[K][N];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>递归版：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">superEggDrop</span><span class="params">(<span class="keyword">int</span> K, <span class="keyword">int</span> N)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] memo = <span class="keyword">new</span> <span class="keyword">int</span>[K + <span class="number">1</span>][N + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">return</span> dfs(K, N, memo);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> K, <span class="keyword">int</span> N, <span class="keyword">int</span>[][] memo)</span></span>&#123;</span><br><span class="line">        <span class="comment">// base case</span></span><br><span class="line">        <span class="keyword">if</span>(N&lt;=<span class="number">1</span> || K==<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> N;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// memorization</span></span><br><span class="line">        <span class="keyword">if</span>(memo[K][N]&gt;<span class="number">0</span>) </span><br><span class="line">            <span class="keyword">return</span> memo[K][N];</span><br><span class="line">        <span class="keyword">int</span> min = N;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; N; i++) &#123;</span><br><span class="line">            <span class="keyword">int</span> left = dfs(K-<span class="number">1</span>, i-<span class="number">1</span>, memo);</span><br><span class="line">            <span class="keyword">int</span> right = dfs(K, N-i, memo);</span><br><span class="line">            min = Math.min(min, Math.max(left, right)+<span class="number">1</span>); </span><br><span class="line">        &#125;</span><br><span class="line">        memo[K][N] = min;</span><br><span class="line">        <span class="keyword">return</span> min;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>这样会超时，优化！从迭代版的代码可以看出，时间复杂度为 $O(KN^2)$,其中搜索$dp[k][n] = min(1+max(dp[k-1][i-1], dp[k][n-i]))  \ i=1…n $中的i可以用二分搜索。从而将时间复杂度将为$O(KNlogN)$.</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">superEggDrop</span><span class="params">(<span class="keyword">int</span> K, <span class="keyword">int</span> N)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] dp = <span class="keyword">new</span> <span class="keyword">int</span>[K+<span class="number">1</span>][N+<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt; K+<span class="number">1</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; N+<span class="number">1</span>; j++) &#123;</span><br><span class="line">                dp[i][j] = j;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">2</span>; i &lt; K+<span class="number">1</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">1</span>; j &lt; N+<span class="number">1</span>; j++) &#123;</span><br><span class="line">                <span class="keyword">int</span> lo =<span class="number">1</span>, hi  = j;</span><br><span class="line">                <span class="keyword">int</span> min = dp[i][j];</span><br><span class="line">                <span class="keyword">while</span>(lo&lt;hi)&#123;</span><br><span class="line">                    <span class="keyword">int</span> mid = lo+(hi-lo)/<span class="number">2</span>;</span><br><span class="line">                    <span class="keyword">int</span> left = dp[i-<span class="number">1</span>][mid-<span class="number">1</span>];</span><br><span class="line">                    <span class="keyword">int</span> right = dp[i][j-mid];</span><br><span class="line">                    min = Math.min(min, Math.max(left, right)+<span class="number">1</span>);</span><br><span class="line">                    <span class="keyword">if</span>(left == right)</span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span>(left &lt; right)</span><br><span class="line">                        lo = mid+<span class="number">1</span>;</span><br><span class="line">                    <span class="keyword">else</span></span><br><span class="line">                        hi = mid;</span><br><span class="line">                &#125;</span><br><span class="line">                dp[i][j] = min;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> dp[K][N];</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>递归版：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">superEggDrop</span><span class="params">(<span class="keyword">int</span> K, <span class="keyword">int</span> N)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span>[][] memo = <span class="keyword">new</span> <span class="keyword">int</span>[K + <span class="number">1</span>][N + <span class="number">1</span>];</span><br><span class="line">        <span class="keyword">return</span> dfs(K, N, memo);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">dfs</span><span class="params">(<span class="keyword">int</span> K, <span class="keyword">int</span> N, <span class="keyword">int</span>[][] memo)</span></span>&#123;</span><br><span class="line">        <span class="comment">// base case</span></span><br><span class="line">        <span class="keyword">if</span>(N&lt;=<span class="number">1</span> || K==<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> N;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// memorization</span></span><br><span class="line">        <span class="keyword">if</span>(memo[K][N]&gt;<span class="number">0</span>) </span><br><span class="line">            <span class="keyword">return</span> memo[K][N];</span><br><span class="line">        <span class="keyword">int</span> lo=<span class="number">1</span>, hi =N, res = N;</span><br><span class="line">        <span class="keyword">while</span>(lo&lt;hi)&#123;</span><br><span class="line">            <span class="keyword">int</span> mid = lo + (hi-lo)/<span class="number">2</span> ;</span><br><span class="line">            <span class="keyword">int</span> left = dfs(K-<span class="number">1</span>, mid-<span class="number">1</span>, memo);</span><br><span class="line">            <span class="keyword">int</span> right = dfs(K, N-mid, memo);</span><br><span class="line">            res = Math.min(res, Math.max(left, right)+<span class="number">1</span>);</span><br><span class="line">            <span class="keyword">if</span>(left==right)&#123;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(left&lt;right)&#123;</span><br><span class="line">                lo = mid+<span class="number">1</span>;</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                hi=mid;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        memo[K][N] = res;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/05/13/并查集原理及联通分量个数问题/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wei">
      <meta itemprop="description" content="有志者，事竟成">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SStarLib's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/05/13/并查集原理及联通分量个数问题/" class="post-title-link" itemprop="url">并查集原理及联通分量个数问题</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2020-05-13 20:39:28 / Modified: 22:14:34" itemprop="dateCreated datePublished" datetime="2020-05-13T20:39:28+08:00">2020-05-13</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="并查集原理及联通分量个数问题"><a href="#并查集原理及联通分量个数问题" class="headerlink" title="并查集原理及联通分量个数问题"></a><center>并查集原理及联通分量个数问题</center></h1><p>[TOC]</p>
<h2 id="一、并查集"><a href="#一、并查集" class="headerlink" title="一、并查集"></a>一、并查集</h2><p>并查集是一个复杂的数据结构。在lc中大概有30道题左右（官方给出）</p>
<h3 id="集合运算"><a href="#集合运算" class="headerlink" title="集合运算"></a>集合运算</h3><p>常见的集合运算有：</p>
<p><code>交、并、补、差、判定一个元素是否属于某一集合</code></p>
<p><strong>并查集：</strong> 集合<code>并、查</code>某元素属于什么集合</p>
<h3 id="存储实现"><a href="#存储实现" class="headerlink" title="存储实现"></a>存储实现</h3><p>使用<code>树结构</code>表示集合，树的每个结点代表一个<code>集合元素</code></p>
<h3 id="图示"><a href="#图示" class="headerlink" title="图示"></a>图示</h3><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ger4k4ug7vj30d305gjrj.jpg" alt="image-20200513205634171"></p>
<p>如图所示有两个集合，如何判定A-I九个元素属于哪个集合？</p>
<blockquote>
<p>例：E 和 C是否为同一个集合。</p>
<p>可以不停的向上查找元素的父节点。判断是否有同一个根节点：</p>
<p>E-&gt;B-&gt;A</p>
<p>C-&gt;A</p>
<p>可见 E和C是同一集合</p>
</blockquote>
<p>实际刷题中往往会给一个<code>关系矩阵</code>, 需要自己创建所有集合。</p>
<p>初始化每个元素为一个集合：</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ger4kkg5udj30gx028glj.jpg" alt="image-20200513210537820"></p>
<p>有九个集合，通过<code>关系矩阵</code>在集合进行并操作：</p>
<blockquote>
<p>例： 在关系矩阵中，A和B在同一集合。则将{A}和{B}并起来。即B指向A。</p>
</blockquote>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ger4p8fuwfj303o038mwz.jpg" alt="image-20200513211007745"></p>
<p>最终构造出由<code>关系矩阵</code>得到的并查集</p>
<h3 id="抽象数据"><a href="#抽象数据" class="headerlink" title="抽象数据"></a>抽象数据</h3><p>元素类型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data, parent=None)</span>:</span></span><br><span class="line">        self.data = data</span><br><span class="line">        self.parent = parent</span><br><span class="line">        </span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DisjointSet</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.map = &#123;&#125;</span><br><span class="line">        self.num_sets = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_set</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        node = Node(data)</span><br><span class="line">        node.parent = node</span><br><span class="line">        self.map[data] = node</span><br><span class="line">        self.num_sets += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">union</span><span class="params">(self, data1, data2)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>随着树的高度的增加，<strong>find</strong>方法进行查询的时候，随着大量的<strong>union</strong>操作调用，导致复杂度的线性上升。导致树结构变成一个类似于线性表的结构。这种变化叫做树的退化，并查集算法需要对此问题进行优化。</p>
<h4 id="定义Rank"><a href="#定义Rank" class="headerlink" title="定义Rank"></a>定义Rank</h4><p>对于每棵树，记录树的高度Rank，当进行union操作，合并两棵树时，如果其Rank不同，那么由Rank小树的连向Rank大的树。</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ger53b6ijcj30eu05sjrm.jpg" alt="image-20200513212325663"></p>
<p><strong>上图中左边的树Rank=3，右边的树Rank=2，Rank小的连向Rank大的。</strong></p>
<h4 id="路径压缩"><a href="#路径压缩" class="headerlink" title="路径压缩"></a>路径压缩</h4><p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ger58lol1qj30av05kwel.jpg" alt="image-20200513212846766"></p>
<p>上图中C的根节点是A，可以直接将C指向A，进行路径压缩操作。</p>
<h3 id="优化后的代码实现"><a href="#优化后的代码实现" class="headerlink" title="优化后的代码实现"></a>优化后的代码实现</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data, parent=None, rank=<span class="number">0</span>)</span>:</span></span><br><span class="line">        self.data = data</span><br><span class="line">        self.parent = parent</span><br><span class="line">        self.rank = rank</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DisjointSet</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.map = &#123;&#125;</span><br><span class="line">        self.num_sets = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_set</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        node = Node(data)</span><br><span class="line">        node.parent = node</span><br><span class="line">        self.map[data]=node</span><br><span class="line">        self.num_sets+=<span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        node = self.map[data]</span><br><span class="line">        r = node</span><br><span class="line">        <span class="keyword">while</span> r!= r.parent:</span><br><span class="line">            r = r.parent</span><br><span class="line">        k = node</span><br><span class="line">        <span class="keyword">while</span> k!=r:</span><br><span class="line">            j = k.parent</span><br><span class="line">            k.parent = r</span><br><span class="line">            k = j</span><br><span class="line">        <span class="keyword">return</span> r</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">union</span><span class="params">(self, data1, data2)</span>:</span></span><br><span class="line">        parent1 = self.find(data1)</span><br><span class="line">        parent2 = self.find(data2)</span><br><span class="line">        <span class="keyword">if</span> parent1.data == parent2.data:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> parent1.rank &gt;= parent2.rank:</span><br><span class="line">            <span class="keyword">if</span> parent1.rank == parent2.rank:</span><br><span class="line">                parent1.rank+=<span class="number">1</span></span><br><span class="line">            parent2.parent = parent1</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            parent1.parent = parent2</span><br><span class="line">        self.num_sets -=<span class="number">1</span></span><br></pre></td></tr></table></figure>

<h3 id="LC-547"><a href="#LC-547" class="headerlink" title="LC #547"></a>LC #547</h3><p>LeetCode第547题的答案就出来了：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, data, parent=None, rank=<span class="number">0</span>)</span>:</span></span><br><span class="line">        self.data = data</span><br><span class="line">        self.parent = parent</span><br><span class="line">        self.rank = rank</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">DisjointSet</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.map = &#123;&#125;</span><br><span class="line">        self.num_sets = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">make_set</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        node = Node(data)</span><br><span class="line">        node.parent = node</span><br><span class="line">        self.map[data]=node</span><br><span class="line">        self.num_sets+=<span class="number">1</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find</span><span class="params">(self, data)</span>:</span></span><br><span class="line">        node = self.map[data]</span><br><span class="line">        r = node</span><br><span class="line">        <span class="keyword">while</span> r!= r.parent:</span><br><span class="line">            r = r.parent</span><br><span class="line">        k = node</span><br><span class="line">        <span class="keyword">while</span> k!=r:</span><br><span class="line">            j = k.parent</span><br><span class="line">            k.parent = r</span><br><span class="line">            k = j</span><br><span class="line">        <span class="keyword">return</span> r</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">union</span><span class="params">(self, data1, data2)</span>:</span></span><br><span class="line">        parent1 = self.find(data1)</span><br><span class="line">        parent2 = self.find(data2)</span><br><span class="line">        <span class="keyword">if</span> parent1.data == parent2.data:</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line">        <span class="keyword">if</span> parent1.rank &gt;= parent2.rank:</span><br><span class="line">            <span class="keyword">if</span> parent1.rank == parent2.rank:</span><br><span class="line">                parent1.rank+=<span class="number">1</span></span><br><span class="line">            parent2.parent = parent1</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            parent1.parent = parent2</span><br><span class="line">        self.num_sets -=<span class="number">1</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">findCircleNum</span><span class="params">(self, M: List[List[int]])</span> -&gt; int:</span></span><br><span class="line">        ds = DisjointSet()</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(M)):</span><br><span class="line">            ds.make_set(i)</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(M)):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(i+<span class="number">1</span>, len(M)):</span><br><span class="line">                <span class="keyword">if</span> M[i][j] == <span class="number">1</span>:</span><br><span class="line">                    ds.union(i, j)</span><br><span class="line">        <span class="keyword">return</span> ds.num_sets</span><br></pre></td></tr></table></figure>


          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/04/24/Pycharm-远程连接-Docker/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Wei">
      <meta itemprop="description" content="有志者，事竟成">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SStarLib's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                
                <a href="/2020/04/24/Pycharm-远程连接-Docker/" class="post-title-link" itemprop="url">Pycharm 远程连接 Docker</a>
              
            
          </h1>
        

        <div class="post-meta">

          
          
          

          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2020-04-24 21:48:10 / Modified: 23:12:50" itemprop="dateCreated datePublished" datetime="2020-04-24T21:48:10+08:00">2020-04-24</time>
            </span>
          

          
            

            
          

          

          
            
            
          

          
          

          

          

          <br>
          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Pycharm-远程连接-Docker"><a href="#Pycharm-远程连接-Docker" class="headerlink" title="Pycharm 远程连接 Docker"></a><center>Pycharm 远程连接 Docker</center></h1><p>[TOC]</p>
<p>引用：<a href="https://zhuanlan.zhihu.com/p/76469329" target="_blank" rel="noopener">pycharm连接远程linux服务器的docker</a></p>
<h2 id="为什么要用pycharm远程连接，-docker"><a href="#为什么要用pycharm远程连接，-docker" class="headerlink" title="为什么要用pycharm远程连接， docker"></a>为什么要用pycharm远程连接， docker</h2><ol>
<li><p>使用docker可以节省安装深度学习环境的时间。</p>
</li>
<li><p>pycharm远程连接为了方便debug</p>
</li>
</ol>
<h2 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h2><ol>
<li><p>首先要有一台服务器，最好装linux系统（推荐centos，稳定，当然稳定就意味着万年不更新）安装显卡驱动。</p>
</li>
<li><p>安装方式docker挺简单的，最好安装nvidia-docker，方便调用GPU，</p>
</li>
<li><p>pull下来一个镜像。</p>
</li>
</ol>
<p>有空的话可以写一篇docker相关的博客（不过如果只是pull下来一个深度学习环境，貌似没啥好写的）</p>
<h2 id="pycharm连接docker"><a href="#pycharm连接docker" class="headerlink" title="pycharm连接docker"></a>pycharm连接docker</h2><ol>
<li>首先运行容器，以我的服务器实际运行命令为例：</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -p 6009:6006 -p 23:22 --name=&quot;torch-remote&quot; -v /root/project:/workspace/project -it --gpus all pytorch_1 /bin/bash</span><br></pre></td></tr></table></figure>

<p>6006端口是用来运行tensorboard的，这里重要的是<strong>22端口</strong>。如果希望通过ssh远程连接docker，需要对容器的<strong>22端口</strong>做端口映射。</p>
<p>更新容器的apt源，安装<strong>ssh</strong>和<strong>vim</strong></p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">apt-get update</span><br><span class="line">apt-get install openssh-server</span><br><span class="line">apt-get install vim</span><br></pre></td></tr></table></figure>

<p>使用vim打开并修改配置文件，找到<code>PermitRootLogin prohibit-password</code>这一行，修改为<code>PermitRootLogin yes</code>，允许通过ssh远程访问docker。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/ssh/sshd_config</span><br></pre></td></tr></table></figure>

<p>创建docker中root用户的密码。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd root</span><br></pre></td></tr></table></figure>

<p>启动ssh服务，至此，服务器端配置完毕。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">service ssh restart</span><br></pre></td></tr></table></figure>

<h3 id="配置pycharm"><a href="#配置pycharm" class="headerlink" title="配置pycharm"></a>配置pycharm</h3><p>在<code>Tools-Deployment-Configuration</code>中，按下图配置。注意<code>Type</code>选择<code>SFTP</code>，<code>Port</code>是步骤1映射的端口，<code>Password</code>是步骤5设置的密码。配置完成后，点击<code>Test SFTP connection</code>，测试连接是否成功。</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ge594wu7huj30m80ilq48.jpg" alt="image-20200424230134133"></p>
<p>配置本地文件上传至docker的目录：</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlgy1ge596pkaq7j30m80ilq47.jpg" alt="image-20200424230318034"></p>
<p>在<code>PyCharm-Preferences-Project Interpreter</code>里，点击右上角的<strong>设置</strong>按钮，选择<code>add remote</code>，配置如下图。注意<code>Python interpreter path</code>指的是docker中python的路径。</p>
<p>![image-20200424230440610](/Users/wei/Library/Application Support/typora-user-images/image-20200424230440610.png)</p>
<p>然后一路next，可能需要更改一下Python interpreter path：改为docker中的python路径即可。</p>
<p>接着需要等待一会，待程序配置结束。点击<code>Tools-Deployment-Automatic Upload</code>打开文件自动上传功能，上传文件需要一定时间。接着我们就可以实现远程运行和调试啦。</p>
<p>![image-20200424230756766](/Users/wei/Library/Application Support/typora-user-images/image-20200424230756766.png)</p>

          
        
      
    </div>

    

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <div class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">

          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  
  <p class="site-author-name" itemprop="name">Wei</p>
  <div class="site-description motion-element" itemprop="description">有志者，事竟成</div>
</div>


  <nav class="site-state motion-element">
    
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">22</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    

    

    
      
      
      <div class="site-state-item site-state-tags">
        
        
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">tags</span>
        
      </div>
    
  </nav>













          
          
        </div>
      </div>

      

      

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wei</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.2.0</div>




        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    

  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>
















  
  









  
  <script src="/lib/jquery/index.js?v=3.4.1"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>




  <script src="/js/utils.js?v=7.2.0"></script>

  <script src="/js/motion.js?v=7.2.0"></script>



  
  


  <script src="/js/affix.js?v=7.2.0"></script>

  <script src="/js/schemes/pisces.js?v=7.2.0"></script>



  

  <script src="/js/next-boot.js?v=7.2.0"></script>

  

  

  


  






























<script>
// GET RESPONSIVE HEIGHT PASSED FROM IFRAME

window.addEventListener("message", function(e) {
  var data = e.data;
  if ((typeof data === 'string') && (data.indexOf('ciu_embed') > -1)) {
    var featureID = data.split(':')[1];
    var height = data.split(':')[2];
    $(`iframe[data-feature=${featureID}]`).height(parseInt(height) + 30);
  }
}, false);
</script>








  

</body>
</html>
